{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a1f1e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook model_functions.ipynb to script\n",
      "[NbConvertApp] Writing 2362 bytes to model_functions.py\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score,RandomizedSearchCV,RepeatedKFold\n",
    "from sklearn.linear_model import Ridge,Lasso, LassoCV,LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from model_functions import label_encoding,training_model,nn_models\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset=pd.read_excel(\"dataset.xlsx\")\n",
    "a=pd.read_excel(\"sample2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fb5ecf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination</th>\n",
       "      <th>Origin</th>\n",
       "      <th>To Area</th>\n",
       "      <th>Flight Date</th>\n",
       "      <th>day_name</th>\n",
       "      <th>flight_month</th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>Flight Code</th>\n",
       "      <th>Days</th>\n",
       "      <th>...</th>\n",
       "      <th>Block1</th>\n",
       "      <th>Sold1</th>\n",
       "      <th>Left1</th>\n",
       "      <th>Occ.(%)1</th>\n",
       "      <th>Occ.</th>\n",
       "      <th>Netto</th>\n",
       "      <th>Netto Currency</th>\n",
       "      <th>Profit</th>\n",
       "      <th>prıce</th>\n",
       "      <th>day_convert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>Belgorod</td>\n",
       "      <td>Antalya</td>\n",
       "      <td>02.01.2020</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>January</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2020</td>\n",
       "      <td>WZ 4035.</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>220</td>\n",
       "      <td>151</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>95.45</td>\n",
       "      <td>177.0</td>\n",
       "      <td>EUR</td>\n",
       "      <td>61.73</td>\n",
       "      <td>238.73</td>\n",
       "      <td>2020-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>Belgorod</td>\n",
       "      <td>Antalya</td>\n",
       "      <td>09.01.2020</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>January</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2020</td>\n",
       "      <td>WZ 4035.</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.00</td>\n",
       "      <td>174.0</td>\n",
       "      <td>EUR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>174.00</td>\n",
       "      <td>2020-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>Chelyabinsk</td>\n",
       "      <td>Antalya</td>\n",
       "      <td>02.01.2020</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>January</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2020</td>\n",
       "      <td>U6 1009</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>220</td>\n",
       "      <td>181</td>\n",
       "      <td>39</td>\n",
       "      <td>82</td>\n",
       "      <td>97.73</td>\n",
       "      <td>253.0</td>\n",
       "      <td>EUR</td>\n",
       "      <td>58.35</td>\n",
       "      <td>311.35</td>\n",
       "      <td>2020-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>Chelyabinsk</td>\n",
       "      <td>Antalya</td>\n",
       "      <td>10.01.2020</td>\n",
       "      <td>Friday</td>\n",
       "      <td>January</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2020</td>\n",
       "      <td>U6 1009</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>220</td>\n",
       "      <td>217</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>236.0</td>\n",
       "      <td>EUR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>236.00</td>\n",
       "      <td>2020-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>Chelyabinsk</td>\n",
       "      <td>Antalya</td>\n",
       "      <td>15.03.2020</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>March</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2020</td>\n",
       "      <td>WZ 4009</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>99.09</td>\n",
       "      <td>251.0</td>\n",
       "      <td>EUR</td>\n",
       "      <td>-50.69</td>\n",
       "      <td>200.31</td>\n",
       "      <td>2020-03-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Destination       Origin  To Area Flight Date  day_name flight_month  \\\n",
       "0      Turkey     Belgorod  Antalya  02.01.2020  Thursday      January   \n",
       "1      Turkey     Belgorod  Antalya  09.01.2020  Thursday      January   \n",
       "2      Turkey  Chelyabinsk  Antalya  02.01.2020  Thursday      January   \n",
       "3      Turkey  Chelyabinsk  Antalya  10.01.2020    Friday      January   \n",
       "4      Turkey  Chelyabinsk  Antalya  15.03.2020    Sunday        March   \n",
       "\n",
       "   season  year Flight Code  Days  ... Block1 Sold1  Left1  Occ.(%)1   Occ.  \\\n",
       "0  Winter  2020    WZ 4035.     4  ...    220   151     69        69  95.45   \n",
       "1  Winter  2020    WZ 4035.     4  ...    220   220      0       100   0.00   \n",
       "2  Winter  2020     U6 1009     4  ...    220   181     39        82  97.73   \n",
       "3  Winter  2020     U6 1009     5  ...    220   217      3        99   0.00   \n",
       "4  Spring  2020     WZ 4009     7  ...    220     1    219         0  99.09   \n",
       "\n",
       "   Netto Netto Currency  Profit   prıce  day_convert  \n",
       "0  177.0            EUR   61.73  238.73   2020-01-02  \n",
       "1  174.0            EUR     NaN  174.00   2020-01-09  \n",
       "2  253.0            EUR   58.35  311.35   2020-01-02  \n",
       "3  236.0            EUR     NaN  236.00   2020-01-10  \n",
       "4  251.0            EUR  -50.69  200.31   2020-03-15  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddb44623",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Days</th>\n",
       "      <th>Block</th>\n",
       "      <th>Sold</th>\n",
       "      <th>Left</th>\n",
       "      <th>Occ.(%)</th>\n",
       "      <th>Block1</th>\n",
       "      <th>Sold1</th>\n",
       "      <th>Left1</th>\n",
       "      <th>Occ.(%)1</th>\n",
       "      <th>Occ.</th>\n",
       "      <th>Netto</th>\n",
       "      <th>Profit</th>\n",
       "      <th>prıce</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.029299</td>\n",
       "      <td>-0.500965</td>\n",
       "      <td>-0.437583</td>\n",
       "      <td>-0.277592</td>\n",
       "      <td>0.202734</td>\n",
       "      <td>-0.500537</td>\n",
       "      <td>-0.436137</td>\n",
       "      <td>-0.241933</td>\n",
       "      <td>0.177326</td>\n",
       "      <td>0.203446</td>\n",
       "      <td>0.673736</td>\n",
       "      <td>0.554636</td>\n",
       "      <td>0.686331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Days</th>\n",
       "      <td>-0.029299</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019128</td>\n",
       "      <td>0.019513</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.025203</td>\n",
       "      <td>0.017977</td>\n",
       "      <td>0.025472</td>\n",
       "      <td>-0.017529</td>\n",
       "      <td>0.026723</td>\n",
       "      <td>0.025176</td>\n",
       "      <td>-0.014492</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>-0.004891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Block</th>\n",
       "      <td>-0.500965</td>\n",
       "      <td>0.019128</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.948956</td>\n",
       "      <td>0.328061</td>\n",
       "      <td>-0.119312</td>\n",
       "      <td>0.998016</td>\n",
       "      <td>0.932570</td>\n",
       "      <td>0.314093</td>\n",
       "      <td>-0.069487</td>\n",
       "      <td>-0.119934</td>\n",
       "      <td>-0.549725</td>\n",
       "      <td>-0.403521</td>\n",
       "      <td>-0.523769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sold</th>\n",
       "      <td>-0.437583</td>\n",
       "      <td>0.019513</td>\n",
       "      <td>0.948956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013363</td>\n",
       "      <td>0.123732</td>\n",
       "      <td>0.947692</td>\n",
       "      <td>0.871648</td>\n",
       "      <td>0.335404</td>\n",
       "      <td>-0.088854</td>\n",
       "      <td>0.123050</td>\n",
       "      <td>-0.500339</td>\n",
       "      <td>-0.348561</td>\n",
       "      <td>-0.454279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Left</th>\n",
       "      <td>-0.277592</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.328061</td>\n",
       "      <td>0.013363</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.748825</td>\n",
       "      <td>0.325558</td>\n",
       "      <td>0.345833</td>\n",
       "      <td>-0.008803</td>\n",
       "      <td>0.045833</td>\n",
       "      <td>-0.748755</td>\n",
       "      <td>-0.244215</td>\n",
       "      <td>-0.269738</td>\n",
       "      <td>-0.299880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Occ.(%)</th>\n",
       "      <td>0.202734</td>\n",
       "      <td>0.025203</td>\n",
       "      <td>-0.119312</td>\n",
       "      <td>0.123732</td>\n",
       "      <td>-0.748825</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.116721</td>\n",
       "      <td>-0.137044</td>\n",
       "      <td>0.038051</td>\n",
       "      <td>-0.039430</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.134688</td>\n",
       "      <td>0.270740</td>\n",
       "      <td>0.265150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Block1</th>\n",
       "      <td>-0.500537</td>\n",
       "      <td>0.017977</td>\n",
       "      <td>0.998016</td>\n",
       "      <td>0.947692</td>\n",
       "      <td>0.325558</td>\n",
       "      <td>-0.116721</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934785</td>\n",
       "      <td>0.313752</td>\n",
       "      <td>-0.068651</td>\n",
       "      <td>-0.117335</td>\n",
       "      <td>-0.549923</td>\n",
       "      <td>-0.403008</td>\n",
       "      <td>-0.523321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sold1</th>\n",
       "      <td>-0.436137</td>\n",
       "      <td>0.025472</td>\n",
       "      <td>0.932570</td>\n",
       "      <td>0.871648</td>\n",
       "      <td>0.345833</td>\n",
       "      <td>-0.137044</td>\n",
       "      <td>0.934785</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.043987</td>\n",
       "      <td>0.182550</td>\n",
       "      <td>-0.137541</td>\n",
       "      <td>-0.497350</td>\n",
       "      <td>-0.360413</td>\n",
       "      <td>-0.471084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Left1</th>\n",
       "      <td>-0.241933</td>\n",
       "      <td>-0.017529</td>\n",
       "      <td>0.314093</td>\n",
       "      <td>0.335404</td>\n",
       "      <td>-0.008803</td>\n",
       "      <td>0.038051</td>\n",
       "      <td>0.313752</td>\n",
       "      <td>-0.043987</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.681047</td>\n",
       "      <td>0.037651</td>\n",
       "      <td>-0.217206</td>\n",
       "      <td>-0.169732</td>\n",
       "      <td>-0.212599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Occ.(%)1</th>\n",
       "      <td>0.177326</td>\n",
       "      <td>0.026723</td>\n",
       "      <td>-0.069487</td>\n",
       "      <td>-0.088854</td>\n",
       "      <td>0.045833</td>\n",
       "      <td>-0.039430</td>\n",
       "      <td>-0.068651</td>\n",
       "      <td>0.182550</td>\n",
       "      <td>-0.681047</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.039222</td>\n",
       "      <td>0.105084</td>\n",
       "      <td>0.156977</td>\n",
       "      <td>0.155612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Occ.</th>\n",
       "      <td>0.203446</td>\n",
       "      <td>0.025176</td>\n",
       "      <td>-0.119934</td>\n",
       "      <td>0.123050</td>\n",
       "      <td>-0.748755</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>-0.117335</td>\n",
       "      <td>-0.137541</td>\n",
       "      <td>0.037651</td>\n",
       "      <td>-0.039222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.135200</td>\n",
       "      <td>0.271347</td>\n",
       "      <td>0.265738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netto</th>\n",
       "      <td>0.673736</td>\n",
       "      <td>-0.014492</td>\n",
       "      <td>-0.549725</td>\n",
       "      <td>-0.500339</td>\n",
       "      <td>-0.244215</td>\n",
       "      <td>0.134688</td>\n",
       "      <td>-0.549923</td>\n",
       "      <td>-0.497350</td>\n",
       "      <td>-0.217206</td>\n",
       "      <td>0.105084</td>\n",
       "      <td>0.135200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.494763</td>\n",
       "      <td>0.784713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profit</th>\n",
       "      <td>0.554636</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>-0.403521</td>\n",
       "      <td>-0.348561</td>\n",
       "      <td>-0.269738</td>\n",
       "      <td>0.270740</td>\n",
       "      <td>-0.403008</td>\n",
       "      <td>-0.360413</td>\n",
       "      <td>-0.169732</td>\n",
       "      <td>0.156977</td>\n",
       "      <td>0.271347</td>\n",
       "      <td>0.494763</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.926078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prıce</th>\n",
       "      <td>0.686331</td>\n",
       "      <td>-0.004891</td>\n",
       "      <td>-0.523769</td>\n",
       "      <td>-0.454279</td>\n",
       "      <td>-0.299880</td>\n",
       "      <td>0.265150</td>\n",
       "      <td>-0.523321</td>\n",
       "      <td>-0.471084</td>\n",
       "      <td>-0.212599</td>\n",
       "      <td>0.155612</td>\n",
       "      <td>0.265738</td>\n",
       "      <td>0.784713</td>\n",
       "      <td>0.926078</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              year      Days     Block      Sold      Left   Occ.(%)  \\\n",
       "year      1.000000 -0.029299 -0.500965 -0.437583 -0.277592  0.202734   \n",
       "Days     -0.029299  1.000000  0.019128  0.019513  0.002197  0.025203   \n",
       "Block    -0.500965  0.019128  1.000000  0.948956  0.328061 -0.119312   \n",
       "Sold     -0.437583  0.019513  0.948956  1.000000  0.013363  0.123732   \n",
       "Left     -0.277592  0.002197  0.328061  0.013363  1.000000 -0.748825   \n",
       "Occ.(%)   0.202734  0.025203 -0.119312  0.123732 -0.748825  1.000000   \n",
       "Block1   -0.500537  0.017977  0.998016  0.947692  0.325558 -0.116721   \n",
       "Sold1    -0.436137  0.025472  0.932570  0.871648  0.345833 -0.137044   \n",
       "Left1    -0.241933 -0.017529  0.314093  0.335404 -0.008803  0.038051   \n",
       "Occ.(%)1  0.177326  0.026723 -0.069487 -0.088854  0.045833 -0.039430   \n",
       "Occ.      0.203446  0.025176 -0.119934  0.123050 -0.748755  0.999966   \n",
       "Netto     0.673736 -0.014492 -0.549725 -0.500339 -0.244215  0.134688   \n",
       "Profit    0.554636  0.003030 -0.403521 -0.348561 -0.269738  0.270740   \n",
       "prıce     0.686331 -0.004891 -0.523769 -0.454279 -0.299880  0.265150   \n",
       "\n",
       "            Block1     Sold1     Left1  Occ.(%)1      Occ.     Netto  \\\n",
       "year     -0.500537 -0.436137 -0.241933  0.177326  0.203446  0.673736   \n",
       "Days      0.017977  0.025472 -0.017529  0.026723  0.025176 -0.014492   \n",
       "Block     0.998016  0.932570  0.314093 -0.069487 -0.119934 -0.549725   \n",
       "Sold      0.947692  0.871648  0.335404 -0.088854  0.123050 -0.500339   \n",
       "Left      0.325558  0.345833 -0.008803  0.045833 -0.748755 -0.244215   \n",
       "Occ.(%)  -0.116721 -0.137044  0.038051 -0.039430  0.999966  0.134688   \n",
       "Block1    1.000000  0.934785  0.313752 -0.068651 -0.117335 -0.549923   \n",
       "Sold1     0.934785  1.000000 -0.043987  0.182550 -0.137541 -0.497350   \n",
       "Left1     0.313752 -0.043987  1.000000 -0.681047  0.037651 -0.217206   \n",
       "Occ.(%)1 -0.068651  0.182550 -0.681047  1.000000 -0.039222  0.105084   \n",
       "Occ.     -0.117335 -0.137541  0.037651 -0.039222  1.000000  0.135200   \n",
       "Netto    -0.549923 -0.497350 -0.217206  0.105084  0.135200  1.000000   \n",
       "Profit   -0.403008 -0.360413 -0.169732  0.156977  0.271347  0.494763   \n",
       "prıce    -0.523321 -0.471084 -0.212599  0.155612  0.265738  0.784713   \n",
       "\n",
       "            Profit     prıce  \n",
       "year      0.554636  0.686331  \n",
       "Days      0.003030 -0.004891  \n",
       "Block    -0.403521 -0.523769  \n",
       "Sold     -0.348561 -0.454279  \n",
       "Left     -0.269738 -0.299880  \n",
       "Occ.(%)   0.270740  0.265150  \n",
       "Block1   -0.403008 -0.523321  \n",
       "Sold1    -0.360413 -0.471084  \n",
       "Left1    -0.169732 -0.212599  \n",
       "Occ.(%)1  0.156977  0.155612  \n",
       "Occ.      0.271347  0.265738  \n",
       "Netto     0.494763  0.784713  \n",
       "Profit    1.000000  0.926078  \n",
       "prıce     0.926078  1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "596128f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Days</th>\n",
       "      <th>Block</th>\n",
       "      <th>Sold</th>\n",
       "      <th>Left</th>\n",
       "      <th>Occ.(%)</th>\n",
       "      <th>Block1</th>\n",
       "      <th>Sold1</th>\n",
       "      <th>Left1</th>\n",
       "      <th>Occ.(%)1</th>\n",
       "      <th>Occ.</th>\n",
       "      <th>Netto</th>\n",
       "      <th>Profit</th>\n",
       "      <th>prıce</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9376.000000</td>\n",
       "      <td>9376.000000</td>\n",
       "      <td>9376.000000</td>\n",
       "      <td>9376.000000</td>\n",
       "      <td>9376.000000</td>\n",
       "      <td>9376.000000</td>\n",
       "      <td>9376.000000</td>\n",
       "      <td>9376.000000</td>\n",
       "      <td>9376.000000</td>\n",
       "      <td>9376.000000</td>\n",
       "      <td>9376.000000</td>\n",
       "      <td>9376.000000</td>\n",
       "      <td>9265.000000</td>\n",
       "      <td>9376.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2021.590444</td>\n",
       "      <td>4.075299</td>\n",
       "      <td>110.070286</td>\n",
       "      <td>100.846416</td>\n",
       "      <td>9.223869</td>\n",
       "      <td>93.901877</td>\n",
       "      <td>109.839484</td>\n",
       "      <td>100.654224</td>\n",
       "      <td>9.185260</td>\n",
       "      <td>93.139078</td>\n",
       "      <td>93.893706</td>\n",
       "      <td>357.159776</td>\n",
       "      <td>244.885018</td>\n",
       "      <td>599.145664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.672453</td>\n",
       "      <td>2.013205</td>\n",
       "      <td>115.047927</td>\n",
       "      <td>108.690466</td>\n",
       "      <td>36.290315</td>\n",
       "      <td>18.139012</td>\n",
       "      <td>114.947229</td>\n",
       "      <td>109.248709</td>\n",
       "      <td>40.870404</td>\n",
       "      <td>20.796022</td>\n",
       "      <td>18.139970</td>\n",
       "      <td>131.830580</td>\n",
       "      <td>215.333670</td>\n",
       "      <td>303.057957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2020.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>-555.910000</td>\n",
       "      <td>-99.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.590000</td>\n",
       "      <td>258.000000</td>\n",
       "      <td>55.920000</td>\n",
       "      <td>346.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>360.245000</td>\n",
       "      <td>229.110000</td>\n",
       "      <td>620.515000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2022.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>405.700000</td>\n",
       "      <td>397.390000</td>\n",
       "      <td>799.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2022.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>478.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>478.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>102.940000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>2552.460000</td>\n",
       "      <td>3255.640000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              year         Days        Block         Sold         Left  \\\n",
       "count  9376.000000  9376.000000  9376.000000  9376.000000  9376.000000   \n",
       "mean   2021.590444     4.075299   110.070286   100.846416     9.223869   \n",
       "std       0.672453     2.013205   115.047927   108.690466    36.290315   \n",
       "min    2020.000000     1.000000     1.000000     0.000000    -4.000000   \n",
       "25%    2021.000000     2.000000    34.000000    30.000000     0.000000   \n",
       "50%    2022.000000     4.000000    63.000000    62.000000     0.000000   \n",
       "75%    2022.000000     6.000000   186.000000   163.000000     1.000000   \n",
       "max    2022.000000     7.000000   492.000000   492.000000   478.000000   \n",
       "\n",
       "           Occ.(%)       Block1        Sold1        Left1     Occ.(%)1  \\\n",
       "count  9376.000000  9376.000000  9376.000000  9376.000000  9376.000000   \n",
       "mean     93.901877   109.839484   100.654224     9.185260    93.139078   \n",
       "std      18.139012   114.947229   109.248709    40.870404    20.796022   \n",
       "min       0.000000     0.000000     0.000000    -6.000000     0.000000   \n",
       "25%     100.000000    34.000000    30.000000     0.000000   100.000000   \n",
       "50%     100.000000    63.000000    62.000000     0.000000   100.000000   \n",
       "75%     100.000000   186.000000   163.000000     0.000000   100.000000   \n",
       "max     103.000000   492.000000   494.000000   478.000000   107.000000   \n",
       "\n",
       "              Occ.        Netto       Profit        prıce  \n",
       "count  9376.000000  9376.000000  9265.000000  9376.000000  \n",
       "mean     93.893706   357.159776   244.885018   599.145664  \n",
       "std      18.139970   131.830580   215.333670   303.057957  \n",
       "min       0.000000    50.000000  -555.910000   -99.210000  \n",
       "25%      99.590000   258.000000    55.920000   346.937500  \n",
       "50%     100.000000   360.245000   229.110000   620.515000  \n",
       "75%     100.000000   405.700000   397.390000   799.690000  \n",
       "max     102.940000   750.000000  2552.460000  3255.640000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b127aa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year      year        1.000000\n",
       "Occ.      Occ.(%)     0.999966\n",
       "Block     Block1      0.998016\n",
       "          Sold        0.948956\n",
       "Sold      Block1      0.947692\n",
       "Block1    Sold1       0.934785\n",
       "Block     Sold1       0.932570\n",
       "Profit    prıce       0.926078\n",
       "Sold1     Sold        0.871648\n",
       "prıce     Netto       0.784713\n",
       "          year        0.686331\n",
       "Netto     year        0.673736\n",
       "year      Profit      0.554636\n",
       "Netto     Profit      0.494763\n",
       "Left      Sold1       0.345833\n",
       "Sold      Left1       0.335404\n",
       "Left      Block       0.328061\n",
       "          Block1      0.325558\n",
       "Left1     Block       0.314093\n",
       "          Block1      0.313752\n",
       "Profit    Occ.        0.271347\n",
       "Occ.(%)   Profit      0.270740\n",
       "prıce     Occ.        0.265738\n",
       "Occ.(%)   prıce       0.265150\n",
       "Occ.      year        0.203446\n",
       "year      Occ.(%)     0.202734\n",
       "Occ.(%)1  Sold1       0.182550\n",
       "          year        0.177326\n",
       "          Profit      0.156977\n",
       "          prıce       0.155612\n",
       "Occ.      Netto       0.135200\n",
       "Netto     Occ.(%)     0.134688\n",
       "Sold      Occ.(%)     0.123732\n",
       "Occ.      Sold        0.123050\n",
       "Occ.(%)1  Netto       0.105084\n",
       "          Left        0.045833\n",
       "Occ.(%)   Left1       0.038051\n",
       "Occ.      Left1       0.037651\n",
       "Days      Occ.(%)1    0.026723\n",
       "Sold1     Days        0.025472\n",
       "Days      Occ.(%)     0.025203\n",
       "          Occ.        0.025176\n",
       "          Sold        0.019513\n",
       "Block     Days        0.019128\n",
       "Days      Block1      0.017977\n",
       "Sold      Left        0.013363\n",
       "Days      Profit      0.003030\n",
       "Left      Days        0.002197\n",
       "Days      prıce      -0.004891\n",
       "Left1     Left       -0.008803\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.corr().unstack().sort_values(ascending=False).drop_duplicates().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f88a292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = dataset.corr()\n",
    "threshold = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9b1ee8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature 1 Feature 2  Correlation\n",
      "21   Occ.(%)      Occ.     0.999966\n",
      "38      Occ.   Occ.(%)     0.999966\n",
      "8      Block    Block1     0.998016\n",
      "22    Block1     Block     0.998016\n",
      "6      Block      Sold     0.948956\n",
      "11      Sold     Block     0.948956\n",
      "13      Sold    Block1     0.947692\n",
      "23    Block1      Sold     0.947692\n",
      "26    Block1     Sold1     0.934785\n",
      "31     Sold1    Block1     0.934785\n",
      "9      Block     Sold1     0.932570\n",
      "28     Sold1     Block     0.932570\n",
      "47    Profit     prıce     0.926078\n",
      "50     prıce    Profit     0.926078\n",
      "14      Sold     Sold1     0.871648\n",
      "29     Sold1      Sold     0.871648\n",
      "49     prıce     Netto     0.784713\n",
      "43     Netto     prıce     0.784713\n",
      "48     prıce      year     0.686331\n",
      "3       year     prıce     0.686331\n",
      "1       year     Netto     0.673736\n",
      "40     Netto      year     0.673736\n",
      "2       year    Profit     0.554636\n",
      "44    Profit      year     0.554636\n",
      "45    Profit     Netto     0.494763\n",
      "42     Netto    Profit     0.494763\n",
      "19      Left     Sold1     0.345833\n",
      "30     Sold1      Left     0.345833\n",
      "15      Sold     Left1     0.335404\n",
      "34     Left1      Sold     0.335404\n",
      "7      Block      Left     0.328061\n",
      "16      Left     Block     0.328061\n",
      "18      Left    Block1     0.325558\n",
      "24    Block1      Left     0.325558\n",
      "33     Left1     Block     0.314093\n",
      "10     Block     Left1     0.314093\n",
      "35     Left1    Block1     0.313752\n",
      "27    Block1     Left1     0.313752\n"
     ]
    }
   ],
   "source": [
    "high_corr = corr_matrix[corr_matrix >= threshold].stack().reset_index()\n",
    "high_corr = high_corr[high_corr['level_0'] != high_corr['level_1']]\n",
    "high_corr = high_corr.rename(columns={'level_0': 'Feature 1', 'level_1': 'Feature 2', 0: 'Correlation'})\n",
    "high_corr = high_corr.sort_values(by='Correlation', ascending=False)\n",
    "\n",
    "print(high_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d9626ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_corr['Feature 1'] = high_corr['Feature 1'].astype(str)\n",
    "high_corr['Feature 2'] = high_corr['Feature 2'].astype(str)\n",
    "core_feature = high_corr['Feature 1'].unique().tolist()\n",
    "core_feature += high_corr['Feature 2'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06c49b65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Occ.(%)',\n",
       " 'Occ.',\n",
       " 'Block',\n",
       " 'Block1',\n",
       " 'Sold',\n",
       " 'Sold1',\n",
       " 'Profit',\n",
       " 'prıce',\n",
       " 'Netto',\n",
       " 'year',\n",
       " 'Left',\n",
       " 'Left1',\n",
       " 'Occ.',\n",
       " 'Occ.(%)',\n",
       " 'Block1',\n",
       " 'Block',\n",
       " 'Sold',\n",
       " 'Sold1',\n",
       " 'prıce',\n",
       " 'Profit',\n",
       " 'Netto',\n",
       " 'year',\n",
       " 'Left',\n",
       " 'Left1']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7447893d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "core_feature=np.unique(core_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14e351a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Destination', 'Origin', 'To Area', 'Flight Date', 'day_name',\n",
       "       'flight_month', 'season', 'year', 'Flight Code', 'Days',\n",
       "       'Airline Company', 'dpt', 'Block', 'Sold', 'Left', 'Occ.(%)', 'dpt1',\n",
       "       'Block1', 'Sold1', 'Left1', 'Occ.(%)1', 'Occ.', 'Netto',\n",
       "       'Netto Currency', 'Profit', 'prıce', 'day_convert'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6af75b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Block</th>\n",
       "      <th>Block1</th>\n",
       "      <th>Left</th>\n",
       "      <th>Left1</th>\n",
       "      <th>Netto</th>\n",
       "      <th>Occ.</th>\n",
       "      <th>Occ.(%)</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Sold</th>\n",
       "      <th>Sold1</th>\n",
       "      <th>prıce</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>10</td>\n",
       "      <td>69</td>\n",
       "      <td>177.00</td>\n",
       "      <td>95.45</td>\n",
       "      <td>95</td>\n",
       "      <td>61.73</td>\n",
       "      <td>210</td>\n",
       "      <td>151</td>\n",
       "      <td>238.73</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>0</td>\n",
       "      <td>174.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>220</td>\n",
       "      <td>174.00</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>253.00</td>\n",
       "      <td>97.73</td>\n",
       "      <td>98</td>\n",
       "      <td>58.35</td>\n",
       "      <td>215</td>\n",
       "      <td>181</td>\n",
       "      <td>311.35</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>3</td>\n",
       "      <td>236.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>236.00</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>2</td>\n",
       "      <td>219</td>\n",
       "      <td>251.00</td>\n",
       "      <td>99.09</td>\n",
       "      <td>99</td>\n",
       "      <td>-50.69</td>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "      <td>200.31</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9371</th>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>377.18</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100</td>\n",
       "      <td>420.95</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>798.13</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9372</th>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>343.18</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100</td>\n",
       "      <td>398.44</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>741.62</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9373</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100</td>\n",
       "      <td>512.82</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>882.82</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9374</th>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>377.18</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100</td>\n",
       "      <td>467.51</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>844.69</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9375</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>703.18</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100</td>\n",
       "      <td>361.37</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1064.55</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9376 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Block  Block1  Left  Left1   Netto    Occ.  Occ.(%)  Profit  Sold  \\\n",
       "0       220     220    10     69  177.00   95.45       95   61.73   210   \n",
       "1       220     220   220      0  174.00    0.00        0     NaN     0   \n",
       "2       220     220     5     39  253.00   97.73       98   58.35   215   \n",
       "3       220     220   220      3  236.00    0.00        0     NaN     0   \n",
       "4       220     220     2    219  251.00   99.09       99  -50.69   218   \n",
       "...     ...     ...   ...    ...     ...     ...      ...     ...   ...   \n",
       "9371     65      65     0      0  377.18  100.00      100  420.95    65   \n",
       "9372     46      46     0      0  343.18  100.00      100  398.44    46   \n",
       "9373     34      34     0      0  370.00  100.00      100  512.82    34   \n",
       "9374     54      54     0      0  377.18  100.00      100  467.51    54   \n",
       "9375      5       5     0      0  703.18  100.00      100  361.37     5   \n",
       "\n",
       "      Sold1    prıce  year  \n",
       "0       151   238.73  2020  \n",
       "1       220   174.00  2020  \n",
       "2       181   311.35  2020  \n",
       "3       217   236.00  2020  \n",
       "4         1   200.31  2020  \n",
       "...     ...      ...   ...  \n",
       "9371     65   798.13  2022  \n",
       "9372     46   741.62  2022  \n",
       "9373     34   882.82  2022  \n",
       "9374     54   844.69  2022  \n",
       "9375      5  1064.55  2022  \n",
       "\n",
       "[9376 rows x 12 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset = dataset.loc[:, core_feature]\n",
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c77b02af",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset=new_dataset.loc[:,['year','Block','Sold','Left','Occ.(%)','Block1','Sold1',\n",
    "                                       'Left1','Occ.','Netto','Profit','prıce']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8384a680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9376 entries, 0 to 9375\n",
      "Data columns (total 12 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   year     9376 non-null   int64  \n",
      " 1   Block    9376 non-null   int64  \n",
      " 2   Sold     9376 non-null   int64  \n",
      " 3   Left     9376 non-null   int64  \n",
      " 4   Occ.(%)  9376 non-null   int64  \n",
      " 5   Block1   9376 non-null   int64  \n",
      " 6   Sold1    9376 non-null   int64  \n",
      " 7   Left1    9376 non-null   int64  \n",
      " 8   Occ.     9376 non-null   float64\n",
      " 9   Netto    9376 non-null   float64\n",
      " 10  Profit   9265 non-null   float64\n",
      " 11  prıce    9376 non-null   float64\n",
      "dtypes: float64(4), int64(8)\n",
      "memory usage: 879.1 KB\n"
     ]
    }
   ],
   "source": [
    "new_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f4e6e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Block</th>\n",
       "      <th>Sold</th>\n",
       "      <th>Left</th>\n",
       "      <th>Occ.(%)</th>\n",
       "      <th>Block1</th>\n",
       "      <th>Sold1</th>\n",
       "      <th>Left1</th>\n",
       "      <th>Occ.</th>\n",
       "      <th>Netto</th>\n",
       "      <th>Profit</th>\n",
       "      <th>prıce</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>220</td>\n",
       "      <td>210</td>\n",
       "      <td>10</td>\n",
       "      <td>95</td>\n",
       "      <td>220</td>\n",
       "      <td>151</td>\n",
       "      <td>69</td>\n",
       "      <td>95.45</td>\n",
       "      <td>177.00</td>\n",
       "      <td>61.73</td>\n",
       "      <td>238.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>220</td>\n",
       "      <td>0</td>\n",
       "      <td>220</td>\n",
       "      <td>0</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>174.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>174.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>220</td>\n",
       "      <td>215</td>\n",
       "      <td>5</td>\n",
       "      <td>98</td>\n",
       "      <td>220</td>\n",
       "      <td>181</td>\n",
       "      <td>39</td>\n",
       "      <td>97.73</td>\n",
       "      <td>253.00</td>\n",
       "      <td>58.35</td>\n",
       "      <td>311.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>220</td>\n",
       "      <td>0</td>\n",
       "      <td>220</td>\n",
       "      <td>0</td>\n",
       "      <td>220</td>\n",
       "      <td>217</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>236.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>236.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>220</td>\n",
       "      <td>218</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>219</td>\n",
       "      <td>99.09</td>\n",
       "      <td>251.00</td>\n",
       "      <td>-50.69</td>\n",
       "      <td>200.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9371</th>\n",
       "      <td>2022</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>377.18</td>\n",
       "      <td>420.95</td>\n",
       "      <td>798.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9372</th>\n",
       "      <td>2022</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>343.18</td>\n",
       "      <td>398.44</td>\n",
       "      <td>741.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9373</th>\n",
       "      <td>2022</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>370.00</td>\n",
       "      <td>512.82</td>\n",
       "      <td>882.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9374</th>\n",
       "      <td>2022</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>377.18</td>\n",
       "      <td>467.51</td>\n",
       "      <td>844.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9375</th>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>703.18</td>\n",
       "      <td>361.37</td>\n",
       "      <td>1064.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9376 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  Block  Sold  Left  Occ.(%)  Block1  Sold1  Left1    Occ.   Netto  \\\n",
       "0     2020    220   210    10       95     220    151     69   95.45  177.00   \n",
       "1     2020    220     0   220        0     220    220      0    0.00  174.00   \n",
       "2     2020    220   215     5       98     220    181     39   97.73  253.00   \n",
       "3     2020    220     0   220        0     220    217      3    0.00  236.00   \n",
       "4     2020    220   218     2       99     220      1    219   99.09  251.00   \n",
       "...    ...    ...   ...   ...      ...     ...    ...    ...     ...     ...   \n",
       "9371  2022     65    65     0      100      65     65      0  100.00  377.18   \n",
       "9372  2022     46    46     0      100      46     46      0  100.00  343.18   \n",
       "9373  2022     34    34     0      100      34     34      0  100.00  370.00   \n",
       "9374  2022     54    54     0      100      54     54      0  100.00  377.18   \n",
       "9375  2022      5     5     0      100       5      5      0  100.00  703.18   \n",
       "\n",
       "      Profit    prıce  \n",
       "0      61.73   238.73  \n",
       "1        NaN   174.00  \n",
       "2      58.35   311.35  \n",
       "3        NaN   236.00  \n",
       "4     -50.69   200.31  \n",
       "...      ...      ...  \n",
       "9371  420.95   798.13  \n",
       "9372  398.44   741.62  \n",
       "9373  512.82   882.82  \n",
       "9374  467.51   844.69  \n",
       "9375  361.37  1064.55  \n",
       "\n",
       "[9376 rows x 12 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a510fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'Block', 'Sold', 'Left', 'Occ.(%)', 'Block1', 'Sold1', 'Left1',\n",
       "       'Occ.', 'Netto', 'Profit', 'prıce'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df17866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoding(dataset, a, 'Destination')\n",
    "label_encoding(dataset, a, 'Origin')\n",
    "label_encoding(dataset, a, 'To Area')\n",
    "label_encoding(dataset, a, 'day_name')\n",
    "label_encoding(dataset, a, 'flight_month')\n",
    "\n",
    "label_encoding(dataset, a, 'season')\n",
    "label_encoding(dataset, a, 'Netto Currency')\n",
    "label_encoding(dataset, a, 'Flight Code')\n",
    "\n",
    "label_encoding(dataset, a, 'Airline Company')\n",
    "label_encoding(dataset, a, 'Flight Date')\n",
    "\n",
    "label_encoding(dataset, a, 'dpt')\n",
    "label_encoding(dataset, a, 'dpt1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8c6ed62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11 entries, 0 to 10\n",
      "Data columns (total 26 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Destination      11 non-null     int64  \n",
      " 1   Origin           11 non-null     int64  \n",
      " 2   To Area          11 non-null     int64  \n",
      " 3   Flight Date      11 non-null     int64  \n",
      " 4   day_name         11 non-null     int64  \n",
      " 5   flight_month     11 non-null     int64  \n",
      " 6   season           11 non-null     int64  \n",
      " 7   year             11 non-null     int64  \n",
      " 8   Flight Code      11 non-null     int64  \n",
      " 9   Days             11 non-null     int64  \n",
      " 10  Airline Company  11 non-null     int64  \n",
      " 11  dpt              11 non-null     int64  \n",
      " 12  Block            11 non-null     int64  \n",
      " 13  Sold             11 non-null     int64  \n",
      " 14  Left             11 non-null     int64  \n",
      " 15  Occ.(%)          11 non-null     int64  \n",
      " 16  dpt1             11 non-null     int64  \n",
      " 17  Block1           11 non-null     int64  \n",
      " 18  Sold1            11 non-null     int64  \n",
      " 19  Left1            11 non-null     int64  \n",
      " 20  Occ.(%)1         11 non-null     int64  \n",
      " 21  Occ.             11 non-null     float64\n",
      " 22  Netto            11 non-null     float64\n",
      " 23  Netto Currency   11 non-null     int64  \n",
      " 24  Profit           11 non-null     float64\n",
      " 25  prıce            11 non-null     float64\n",
      "dtypes: float64(4), int64(22)\n",
      "memory usage: 2.4 KB\n"
     ]
    }
   ],
   "source": [
    "a.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76cf7a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset[\"Profit\"]=new_dataset[\"Profit\"].fillna(new_dataset[\"Profit\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de14c23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_dataset.drop(['prıce'], axis=1)\n",
    "y = new_dataset.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ed6a5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y.values.ravel(), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a1c9838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor()\n",
    "\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.0001,0.001, 0.01, 0.1, 1] ,\n",
    "    \"max_depth\": range(3,21,3),\n",
    "    \"gamma\": [i/10.0 for i in range(0,5)],\n",
    "    \"colsample_bytree\": [i/10.0 for i in range(3,10)],\n",
    "    \"reg_alpha\": [1e-5, 1e-2, 0.1, 1, 10, 100],\n",
    "    \"reg_lambda\": [1e-5, 1e-2, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "xgb_cv = RandomizedSearchCV(xgb, param_grid, n_iter = 100, refit='recall',\n",
    "         scoring='neg_mean_squared_error', cv = 5, verbose=2, random_state=42, n_jobs = -1) \n",
    "xgb_cv.fit(X_train, y_train)\n",
    "xgb_reg = XGBRegressor(**xgb_cv.best_params_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "82657abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Block</th>\n",
       "      <th>Sold</th>\n",
       "      <th>Left</th>\n",
       "      <th>Occ.(%)</th>\n",
       "      <th>Block1</th>\n",
       "      <th>Sold1</th>\n",
       "      <th>Left1</th>\n",
       "      <th>Occ.</th>\n",
       "      <th>Netto</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021</td>\n",
       "      <td>220</td>\n",
       "      <td>144</td>\n",
       "      <td>76</td>\n",
       "      <td>65</td>\n",
       "      <td>220</td>\n",
       "      <td>212</td>\n",
       "      <td>8</td>\n",
       "      <td>65.45</td>\n",
       "      <td>149.00</td>\n",
       "      <td>-32.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>189</td>\n",
       "      <td>134</td>\n",
       "      <td>55</td>\n",
       "      <td>71</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "      <td>70.90</td>\n",
       "      <td>246.00</td>\n",
       "      <td>-42.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>475.82</td>\n",
       "      <td>562.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>660.36</td>\n",
       "      <td>647.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021</td>\n",
       "      <td>163</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>163</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>356.36</td>\n",
       "      <td>318.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022</td>\n",
       "      <td>492</td>\n",
       "      <td>489</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>478</td>\n",
       "      <td>8</td>\n",
       "      <td>470</td>\n",
       "      <td>99.39</td>\n",
       "      <td>162.00</td>\n",
       "      <td>81.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022</td>\n",
       "      <td>475</td>\n",
       "      <td>473</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>474</td>\n",
       "      <td>0</td>\n",
       "      <td>474</td>\n",
       "      <td>99.58</td>\n",
       "      <td>150.00</td>\n",
       "      <td>153.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022</td>\n",
       "      <td>328</td>\n",
       "      <td>326</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>328</td>\n",
       "      <td>322</td>\n",
       "      <td>6</td>\n",
       "      <td>99.39</td>\n",
       "      <td>162.00</td>\n",
       "      <td>22.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022</td>\n",
       "      <td>119</td>\n",
       "      <td>114</td>\n",
       "      <td>5</td>\n",
       "      <td>96</td>\n",
       "      <td>110</td>\n",
       "      <td>82</td>\n",
       "      <td>28</td>\n",
       "      <td>95.80</td>\n",
       "      <td>200.00</td>\n",
       "      <td>75.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022</td>\n",
       "      <td>235</td>\n",
       "      <td>55</td>\n",
       "      <td>180</td>\n",
       "      <td>23</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>23.40</td>\n",
       "      <td>259.00</td>\n",
       "      <td>68.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021</td>\n",
       "      <td>213</td>\n",
       "      <td>113</td>\n",
       "      <td>100</td>\n",
       "      <td>53</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>0</td>\n",
       "      <td>53.05</td>\n",
       "      <td>197.00</td>\n",
       "      <td>-74.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  Block  Sold  Left  Occ.(%)  Block1  Sold1  Left1    Occ.   Netto  \\\n",
       "0   2021    220   144    76       65     220    212      8   65.45  149.00   \n",
       "1   2022    189   134    55       71     189    189      0   70.90  246.00   \n",
       "2   2022     58    58     0      100      58     58      0  100.00  475.82   \n",
       "3   2022     16    16     0      100      14     14      0  100.00  660.36   \n",
       "4   2021    163   163     0      100     163    163      0  100.00  356.36   \n",
       "5   2022    492   489     3       99     478      8    470   99.39  162.00   \n",
       "6   2022    475   473     2      100     474      0    474   99.58  150.00   \n",
       "7   2022    328   326     2       99     328    322      6   99.39  162.00   \n",
       "8   2022    119   114     5       96     110     82     28   95.80  200.00   \n",
       "9   2022    235    55   180       23     235    235      0   23.40  259.00   \n",
       "10  2021    213   113   100       53     220    220      0   53.05  197.00   \n",
       "\n",
       "    Profit  \n",
       "0   -32.53  \n",
       "1   -42.98  \n",
       "2   562.33  \n",
       "3   647.46  \n",
       "4   318.20  \n",
       "5    81.50  \n",
       "6   153.87  \n",
       "7    22.08  \n",
       "8    75.78  \n",
       "9    68.88  \n",
       "10  -74.97  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample2 = a.loc[:,['year', 'Block', 'Sold', 'Left', 'Occ.(%)', 'Block1', 'Sold1', 'Left1',\n",
    "       'Occ.', 'Netto', 'Profit']]\n",
    "sample2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "87c59a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = RandomForestRegressor(n_estimators = 11, max_depth = 30,min_samples_split=5,random_state = 42)\n",
    "DT_Regressor = tree.DecisionTreeRegressor()\n",
    "ridge = Ridge(alpha=1.0)\n",
    "lasso_cv = LassoCV(alphas = None, cv = 10, max_iter = 100000, normalize = True)\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e0be31bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = { 'Random forest': rf2,'Decision tree': DT_Regressor,'Ridge regression': ridge,\n",
    "          'Lasso regression': lasso_cv,'Linear regression': lr,'XGBOOST': xgb_reg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4a76515e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^squared: 0.9972743774907535\n",
      "MSE:  248.90326143829625\n",
      "RMSE:  15.776668261654494\n",
      "MAE: 5.101360360308412\n",
      "R^squared: 0.998386120004096\n",
      "MSE:  147.37917418416805\n",
      "RMSE:  12.13998246226773\n",
      "MAE: 5.213373182552497\n",
      "R^squared: 0.9939509300910401\n",
      "MSE:  552.3997633203554\n",
      "RMSE:  23.503186237622238\n",
      "MAE: 7.43217273276021\n",
      "R^squared: 0.9939384909281549\n",
      "MSE:  553.5357050001727\n",
      "RMSE:  23.52733952235511\n",
      "MAE: 7.455243716383414\n",
      "R^squared: 0.9939507489113729\n",
      "MSE:  552.4163086086008\n",
      "RMSE:  23.503538214673146\n",
      "MAE: 7.421801515129494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\90541\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^squared: 0.9985146530106427\n",
      "MSE:  135.64156766550568\n",
      "RMSE:  11.646525991277642\n",
      "MAE: 5.144974270994734\n"
     ]
    }
   ],
   "source": [
    "model_outputs = {}\n",
    "sample_predicted={}\n",
    "\n",
    "for i, (key, model) in enumerate(models.items()):\n",
    "    model, score, mse, rmse, mae = training_model(X_train, X_test, y_train, y_test, model=model)\n",
    "    model_outputs[key] = {'R-squared': score, 'MSE': mse, 'RMSE': rmse, 'MAE': mae}\n",
    "    sample_predicted[key]=model.predict(sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "791ec0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random forest</th>\n",
       "      <th>Decision tree</th>\n",
       "      <th>Ridge regression</th>\n",
       "      <th>Lasso regression</th>\n",
       "      <th>Linear regression</th>\n",
       "      <th>XGBOOST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>0.997274</td>\n",
       "      <td>0.998386</td>\n",
       "      <td>0.993951</td>\n",
       "      <td>0.993938</td>\n",
       "      <td>0.993951</td>\n",
       "      <td>0.998515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>248.903261</td>\n",
       "      <td>147.379174</td>\n",
       "      <td>552.399763</td>\n",
       "      <td>553.535705</td>\n",
       "      <td>552.416309</td>\n",
       "      <td>135.641568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>15.776668</td>\n",
       "      <td>12.139982</td>\n",
       "      <td>23.503186</td>\n",
       "      <td>23.527340</td>\n",
       "      <td>23.503538</td>\n",
       "      <td>11.646526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>5.101360</td>\n",
       "      <td>5.213373</td>\n",
       "      <td>7.432173</td>\n",
       "      <td>7.455244</td>\n",
       "      <td>7.421802</td>\n",
       "      <td>5.144974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Random forest  Decision tree  Ridge regression  Lasso regression  \\\n",
       "R-squared       0.997274       0.998386          0.993951          0.993938   \n",
       "MSE           248.903261     147.379174        552.399763        553.535705   \n",
       "RMSE           15.776668      12.139982         23.503186         23.527340   \n",
       "MAE             5.101360       5.213373          7.432173          7.455244   \n",
       "\n",
       "           Linear regression     XGBOOST  \n",
       "R-squared           0.993951    0.998515  \n",
       "MSE               552.416309  135.641568  \n",
       "RMSE               23.503538   11.646526  \n",
       "MAE                 7.421802    5.144974  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_outputs = pd.DataFrame(model_outputs)\n",
    "model_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "99ed6e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_predicted = pd.DataFrame(sample_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bc6f89c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prıce</th>\n",
       "      <th>Random forest</th>\n",
       "      <th>Decision tree</th>\n",
       "      <th>Ridge regression</th>\n",
       "      <th>Lasso regression</th>\n",
       "      <th>Linear regression</th>\n",
       "      <th>XGBOOST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116.47</td>\n",
       "      <td>114.818515</td>\n",
       "      <td>113.84</td>\n",
       "      <td>97.743018</td>\n",
       "      <td>98.115516</td>\n",
       "      <td>97.864415</td>\n",
       "      <td>115.148003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>203.02</td>\n",
       "      <td>189.777538</td>\n",
       "      <td>200.31</td>\n",
       "      <td>189.175599</td>\n",
       "      <td>189.720154</td>\n",
       "      <td>189.373304</td>\n",
       "      <td>197.581696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1038.15</td>\n",
       "      <td>1046.139410</td>\n",
       "      <td>1051.36</td>\n",
       "      <td>1035.601689</td>\n",
       "      <td>1035.169251</td>\n",
       "      <td>1035.635449</td>\n",
       "      <td>1038.028687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1307.82</td>\n",
       "      <td>1304.225297</td>\n",
       "      <td>1305.01</td>\n",
       "      <td>1303.945537</td>\n",
       "      <td>1303.331208</td>\n",
       "      <td>1303.961293</td>\n",
       "      <td>1303.974854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>674.56</td>\n",
       "      <td>645.919634</td>\n",
       "      <td>671.63</td>\n",
       "      <td>674.672911</td>\n",
       "      <td>674.533879</td>\n",
       "      <td>674.655169</td>\n",
       "      <td>597.222046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>243.50</td>\n",
       "      <td>243.460384</td>\n",
       "      <td>243.50</td>\n",
       "      <td>242.700485</td>\n",
       "      <td>245.655570</td>\n",
       "      <td>242.178885</td>\n",
       "      <td>261.004456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>303.87</td>\n",
       "      <td>298.873838</td>\n",
       "      <td>303.87</td>\n",
       "      <td>302.582371</td>\n",
       "      <td>305.606310</td>\n",
       "      <td>301.979184</td>\n",
       "      <td>333.570221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>184.08</td>\n",
       "      <td>183.313853</td>\n",
       "      <td>184.08</td>\n",
       "      <td>188.897722</td>\n",
       "      <td>188.958619</td>\n",
       "      <td>189.080536</td>\n",
       "      <td>172.432922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>275.78</td>\n",
       "      <td>275.148063</td>\n",
       "      <td>275.78</td>\n",
       "      <td>276.926182</td>\n",
       "      <td>277.666584</td>\n",
       "      <td>277.014163</td>\n",
       "      <td>307.721222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>327.88</td>\n",
       "      <td>314.025727</td>\n",
       "      <td>327.88</td>\n",
       "      <td>279.531873</td>\n",
       "      <td>280.144214</td>\n",
       "      <td>279.909633</td>\n",
       "      <td>308.804169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>122.03</td>\n",
       "      <td>113.683972</td>\n",
       "      <td>128.72</td>\n",
       "      <td>95.655654</td>\n",
       "      <td>96.112437</td>\n",
       "      <td>95.778004</td>\n",
       "      <td>118.304466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prıce  Random forest  Decision tree  Ridge regression  Lasso regression  \\\n",
       "0    116.47     114.818515         113.84         97.743018         98.115516   \n",
       "1    203.02     189.777538         200.31        189.175599        189.720154   \n",
       "2   1038.15    1046.139410        1051.36       1035.601689       1035.169251   \n",
       "3   1307.82    1304.225297        1305.01       1303.945537       1303.331208   \n",
       "4    674.56     645.919634         671.63        674.672911        674.533879   \n",
       "5    243.50     243.460384         243.50        242.700485        245.655570   \n",
       "6    303.87     298.873838         303.87        302.582371        305.606310   \n",
       "7    184.08     183.313853         184.08        188.897722        188.958619   \n",
       "8    275.78     275.148063         275.78        276.926182        277.666584   \n",
       "9    327.88     314.025727         327.88        279.531873        280.144214   \n",
       "10   122.03     113.683972         128.72         95.655654         96.112437   \n",
       "\n",
       "    Linear regression      XGBOOST  \n",
       "0           97.864415   115.148003  \n",
       "1          189.373304   197.581696  \n",
       "2         1035.635449  1038.028687  \n",
       "3         1303.961293  1303.974854  \n",
       "4          674.655169   597.222046  \n",
       "5          242.178885   261.004456  \n",
       "6          301.979184   333.570221  \n",
       "7          189.080536   172.432922  \n",
       "8          277.014163   307.721222  \n",
       "9          279.909633   308.804169  \n",
       "10          95.778004   118.304466  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_pred=pd.concat([a[['prıce']],sample_predicted], axis=1)\n",
    "real_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ae57603a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from tensorflow.python.keras.layers import Dense, LSTM, RepeatVector, Flatten,SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6b76084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b858eec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape (6281, 11)\n",
      "Test shape (3095, 11)\n"
     ]
    }
   ],
   "source": [
    "print('Train shape', X_train_scaled.shape)\n",
    "print('Test shape', X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ffb2774a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input [samples, time steps, features] for LSTM\n",
    "X_train_items = np.reshape(X_train_scaled, (X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
    "X_test_items = np.reshape(X_test_scaled, (X_test_scaled.shape[0], X_test_scaled.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4e29a680",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(500, 50), max_iter=2000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fdaa703d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modellstm = Sequential()\n",
    "modellstm.add(LSTM(50, input_shape=(X_train_items.shape[1], 1)))\n",
    "modellstm.add(Dense(1))\n",
    "modellstm.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "179c542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = Sequential()\n",
    "rnn.add(SimpleRNN(units=20, input_shape=(X_train_items.shape[1], X_train_items.shape[2])))\n",
    "rnn.add(Dense(1))\n",
    "rnn.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "342150a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = { 'MLP': mlp,'LSTM': modellstm,'RNN': rnn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "71a92906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^squared: 0.9968270195984388\n",
      "MSE:  289.755887966575\n",
      "RMSE:  17.022217480885825\n",
      "MAE: 4.49426715376861\n",
      "Epoch 1/200\n",
      "393/393 [==============================] - 3s 4ms/step - loss: 426460.2812\n",
      "Epoch 2/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 401589.2812\n",
      "Epoch 3/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 380029.0938\n",
      "Epoch 4/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 359757.2812\n",
      "Epoch 5/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 340552.8438\n",
      "Epoch 6/200\n",
      "393/393 [==============================] - 2s 6ms/step - loss: 322286.0312\n",
      "Epoch 7/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 304916.8750\n",
      "Epoch 8/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 288399.9062\n",
      "Epoch 9/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 272699.5000\n",
      "Epoch 10/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 257759.2656\n",
      "Epoch 11/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 243568.9219\n",
      "Epoch 12/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 230131.6094\n",
      "Epoch 13/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 217424.1875\n",
      "Epoch 14/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 205407.0938\n",
      "Epoch 15/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 194096.7188\n",
      "Epoch 16/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 183470.6094\n",
      "Epoch 17/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 173524.4844\n",
      "Epoch 18/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 164246.5156\n",
      "Epoch 19/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 155631.7969\n",
      "Epoch 20/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 147658.3594\n",
      "Epoch 21/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 140325.3125\n",
      "Epoch 22/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 133609.5000\n",
      "Epoch 23/200\n",
      "393/393 [==============================] - 3s 7ms/step - loss: 127488.0625\n",
      "Epoch 24/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 121970.1016\n",
      "Epoch 25/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 117037.7031\n",
      "Epoch 26/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 112648.3828\n",
      "Epoch 27/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 108802.4844\n",
      "Epoch 28/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 105540.2656\n",
      "Epoch 29/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 102646.6484\n",
      "Epoch 30/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 100245.9922\n",
      "Epoch 31/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 98272.6094\n",
      "Epoch 32/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 96683.0391\n",
      "Epoch 33/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 95398.5078\n",
      "Epoch 34/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 94422.3750\n",
      "Epoch 35/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 91434.9375\n",
      "Epoch 36/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 69543.9219\n",
      "Epoch 37/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 64048.9141\n",
      "Epoch 38/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 60312.3008\n",
      "Epoch 39/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 60818.1172\n",
      "Epoch 40/200\n",
      "393/393 [==============================] - 2s 6ms/step - loss: 54042.4297\n",
      "Epoch 41/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 50134.9688\n",
      "Epoch 42/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 55936.9492\n",
      "Epoch 43/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 45837.5195\n",
      "Epoch 44/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 44232.9062\n",
      "Epoch 45/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 43325.4258\n",
      "Epoch 46/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 42660.3398\n",
      "Epoch 47/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 42195.6172\n",
      "Epoch 48/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 41879.0742\n",
      "Epoch 49/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 41631.1758\n",
      "Epoch 50/200\n",
      "393/393 [==============================] - 2s 6ms/step - loss: 41306.8711\n",
      "Epoch 51/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 41182.5742\n",
      "Epoch 52/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 41117.8086\n",
      "Epoch 53/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 40706.8633\n",
      "Epoch 54/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 40355.0625\n",
      "Epoch 55/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 40032.3047\n",
      "Epoch 56/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 39767.4727\n",
      "Epoch 57/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 39571.9414\n",
      "Epoch 58/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 39224.2383\n",
      "Epoch 59/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 38720.8242\n",
      "Epoch 60/200\n",
      "393/393 [==============================] - 2s 6ms/step - loss: 39597.2930\n",
      "Epoch 61/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 39793.9805\n",
      "Epoch 62/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 39826.5898\n",
      "Epoch 63/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 37868.9375\n",
      "Epoch 64/200\n",
      "393/393 [==============================] - 2s 6ms/step - loss: 36724.0820\n",
      "Epoch 65/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 35523.9492\n",
      "Epoch 66/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 34537.1719\n",
      "Epoch 67/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 33530.0742\n",
      "Epoch 68/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 32954.8203\n",
      "Epoch 69/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 31832.8848\n",
      "Epoch 70/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 31740.9082\n",
      "Epoch 71/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 30470.4707\n",
      "Epoch 72/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 29896.7402\n",
      "Epoch 73/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 28664.8828\n",
      "Epoch 74/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 28323.7148\n",
      "Epoch 75/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 27418.8203\n",
      "Epoch 76/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 27147.8613\n",
      "Epoch 77/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 25963.2715\n",
      "Epoch 78/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 25356.9668\n",
      "Epoch 79/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 24507.0840\n",
      "Epoch 80/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 24063.2129\n",
      "Epoch 81/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 23155.2500\n",
      "Epoch 82/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 22952.8320\n",
      "Epoch 83/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 22102.8652\n",
      "Epoch 84/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 21824.9883\n",
      "Epoch 85/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 21108.1387\n",
      "Epoch 86/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 20566.1855\n",
      "Epoch 87/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 20249.9102\n",
      "Epoch 88/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 19332.6113\n",
      "Epoch 89/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 18977.9883\n",
      "Epoch 90/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 18493.8828\n",
      "Epoch 91/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 17971.1582\n",
      "Epoch 92/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 17198.0039\n",
      "Epoch 93/200\n",
      "393/393 [==============================] - 2s 6ms/step - loss: 16717.3438\n",
      "Epoch 94/200\n",
      "393/393 [==============================] - 2s 6ms/step - loss: 15956.5625\n",
      "Epoch 95/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 15374.3711\n",
      "Epoch 96/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 14659.6670\n",
      "Epoch 97/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 13732.0430\n",
      "Epoch 98/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 13177.3369\n",
      "Epoch 99/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 12603.8945\n",
      "Epoch 100/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 12051.4170\n",
      "Epoch 101/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 11525.0078\n",
      "Epoch 102/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 10992.4385\n",
      "Epoch 103/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 10546.2686\n",
      "Epoch 104/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 9955.5742\n",
      "Epoch 105/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 9449.2383\n",
      "Epoch 106/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 8906.9961\n",
      "Epoch 107/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 8537.2090\n",
      "Epoch 108/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 8145.8457\n",
      "Epoch 109/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 7793.4175\n",
      "Epoch 110/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 7368.7720\n",
      "Epoch 111/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 7066.6387\n",
      "Epoch 112/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 6747.0225\n",
      "Epoch 113/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 6479.7231\n",
      "Epoch 114/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 6125.3086\n",
      "Epoch 115/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 5866.0244\n",
      "Epoch 116/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 5580.6787\n",
      "Epoch 117/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 5340.1152\n",
      "Epoch 118/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 5096.8828\n",
      "Epoch 119/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 4842.6724\n",
      "Epoch 120/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 4644.0991\n",
      "Epoch 121/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 4400.0479\n",
      "Epoch 122/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 4191.3926\n",
      "Epoch 123/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 4012.1235\n",
      "Epoch 124/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 3849.5581\n",
      "Epoch 125/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 3690.6711\n",
      "Epoch 126/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 3597.5806\n",
      "Epoch 127/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 3471.9966\n",
      "Epoch 128/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 3361.2212\n",
      "Epoch 129/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 3227.1484\n",
      "Epoch 130/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 3167.4048\n",
      "Epoch 131/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 3055.6182\n",
      "Epoch 132/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 2956.2839\n",
      "Epoch 133/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 2886.8416\n",
      "Epoch 134/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 2832.6511\n",
      "Epoch 135/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 2718.3494\n",
      "Epoch 136/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 2674.2898\n",
      "Epoch 137/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 2607.6411\n",
      "Epoch 138/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 2523.6680\n",
      "Epoch 139/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 2472.2188\n",
      "Epoch 140/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 2415.8271\n",
      "Epoch 141/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 2367.8145\n",
      "Epoch 142/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 2329.8267\n",
      "Epoch 143/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 2280.6262\n",
      "Epoch 144/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 2221.2505\n",
      "Epoch 145/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 2185.9451\n",
      "Epoch 146/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 2147.0552\n",
      "Epoch 147/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 2091.3906\n",
      "Epoch 148/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 2064.3069\n",
      "Epoch 149/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 2010.1754\n",
      "Epoch 150/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 1997.0764\n",
      "Epoch 151/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 1962.5861\n",
      "Epoch 152/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 1937.9567\n",
      "Epoch 153/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 1900.8912\n",
      "Epoch 154/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 1858.8521\n",
      "Epoch 155/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 1813.7841\n",
      "Epoch 156/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 1815.8409\n",
      "Epoch 157/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 1784.6182\n",
      "Epoch 158/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 1752.3700\n",
      "Epoch 159/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 1744.7247\n",
      "Epoch 160/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 1684.1035\n",
      "Epoch 161/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 1682.8236\n",
      "Epoch 162/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 1649.3323\n",
      "Epoch 163/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 1639.2444\n",
      "Epoch 164/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 1621.0543\n",
      "Epoch 165/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 1592.6281\n",
      "Epoch 166/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 1563.8367\n",
      "Epoch 167/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 1547.1748\n",
      "Epoch 168/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 1546.9136\n",
      "Epoch 169/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 1536.1729\n",
      "Epoch 170/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 1491.8368\n",
      "Epoch 171/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 1471.7975\n",
      "Epoch 172/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 1460.5913\n",
      "Epoch 173/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 1459.8682\n",
      "Epoch 174/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 1431.0775\n",
      "Epoch 175/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 1413.2151\n",
      "Epoch 176/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 1408.4039\n",
      "Epoch 177/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 1398.3187\n",
      "Epoch 178/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 1393.1127\n",
      "Epoch 179/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 1349.6388\n",
      "Epoch 180/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 1353.4133\n",
      "Epoch 181/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 1337.7341\n",
      "Epoch 182/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 1344.3004\n",
      "Epoch 183/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 1292.5775\n",
      "Epoch 184/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 1309.5691\n",
      "Epoch 185/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 1311.0555\n",
      "Epoch 186/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 1278.9081\n",
      "Epoch 187/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393/393 [==============================] - 2s 5ms/step - loss: 1276.0596\n",
      "Epoch 188/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 1252.9425\n",
      "Epoch 189/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 1246.8264\n",
      "Epoch 190/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 1237.6992\n",
      "Epoch 191/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 1220.6710\n",
      "Epoch 192/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 1209.4661\n",
      "Epoch 193/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 1204.4553\n",
      "Epoch 194/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 1185.9669\n",
      "Epoch 195/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 1184.0776\n",
      "Epoch 196/200\n",
      "393/393 [==============================] - 2s 6ms/step - loss: 1166.1237\n",
      "Epoch 197/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 1174.3926\n",
      "Epoch 198/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 1157.6746\n",
      "Epoch 199/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 1150.1163\n",
      "Epoch 200/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 1139.7809\n",
      "97/97 [==============================] - 1s 1ms/step\n",
      "R^squared: 0.9888072756932837\n",
      "MSE:  1022.11717685424\n",
      "RMSE:  31.97056735271115\n",
      "MAE: 9.041862119745883\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "Epoch 1/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 437879.0938\n",
      "Epoch 2/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 425810.2188\n",
      "Epoch 3/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 415986.6250\n",
      "Epoch 4/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 406649.7812\n",
      "Epoch 5/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 397581.6875\n",
      "Epoch 6/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 388728.4062\n",
      "Epoch 7/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 380062.8750\n",
      "Epoch 8/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 371569.5625\n",
      "Epoch 9/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 363233.4062\n",
      "Epoch 10/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 355057.8125\n",
      "Epoch 11/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 347029.0000\n",
      "Epoch 12/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 339138.1562\n",
      "Epoch 13/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 331388.3438\n",
      "Epoch 14/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 323773.0625\n",
      "Epoch 15/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 316288.4375\n",
      "Epoch 16/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 308930.9062\n",
      "Epoch 17/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 301701.8750\n",
      "Epoch 18/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 294612.2188\n",
      "Epoch 19/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 287654.0938\n",
      "Epoch 20/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 280827.5625\n",
      "Epoch 21/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 274125.6875\n",
      "Epoch 22/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 267557.5000\n",
      "Epoch 23/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 261127.9219\n",
      "Epoch 24/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 254816.2344\n",
      "Epoch 25/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 248636.2344\n",
      "Epoch 26/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 242591.2188\n",
      "Epoch 27/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 236674.6562\n",
      "Epoch 28/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 230884.4062\n",
      "Epoch 29/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 225217.0156\n",
      "Epoch 30/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 219677.3125\n",
      "Epoch 31/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 214268.0000\n",
      "Epoch 32/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 208986.5156\n",
      "Epoch 33/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 203829.4688\n",
      "Epoch 34/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 198802.2031\n",
      "Epoch 35/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 193902.8750\n",
      "Epoch 36/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 189126.4688\n",
      "Epoch 37/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 184487.9219\n",
      "Epoch 38/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 179970.5000\n",
      "Epoch 39/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 175573.8750\n",
      "Epoch 40/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 171299.0938\n",
      "Epoch 41/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 167147.4688\n",
      "Epoch 42/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 163124.0938\n",
      "Epoch 43/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 159229.2500\n",
      "Epoch 44/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 155464.3594\n",
      "Epoch 45/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 151814.9219\n",
      "Epoch 46/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 148284.7812\n",
      "Epoch 47/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 144875.3750\n",
      "Epoch 48/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 141585.3906\n",
      "Epoch 49/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 138409.6406\n",
      "Epoch 50/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 135361.3281\n",
      "Epoch 51/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 132437.4688\n",
      "Epoch 52/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 129636.9766\n",
      "Epoch 53/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 126953.7344\n",
      "Epoch 54/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 124388.3828\n",
      "Epoch 55/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 122201.3203\n",
      "Epoch 56/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 119585.6953\n",
      "Epoch 57/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 117365.2188\n",
      "Epoch 58/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 115253.1875\n",
      "Epoch 59/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 113258.7969\n",
      "Epoch 60/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 111371.3203\n",
      "Epoch 61/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 109590.6016\n",
      "Epoch 62/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 107920.6328\n",
      "Epoch 63/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 106361.6797\n",
      "Epoch 64/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 104908.8047\n",
      "Epoch 65/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 103555.7500\n",
      "Epoch 66/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 102303.1094\n",
      "Epoch 67/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 101145.7969\n",
      "Epoch 68/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 100084.8906\n",
      "Epoch 69/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 99120.6016\n",
      "Epoch 70/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 98247.7734\n",
      "Epoch 71/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 97452.4531\n",
      "Epoch 72/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 96730.5938\n",
      "Epoch 73/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 96086.0156\n",
      "Epoch 74/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 95511.5781\n",
      "Epoch 75/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 95004.9297\n",
      "Epoch 76/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 94561.2188\n",
      "Epoch 77/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 94172.6328\n",
      "Epoch 78/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 93833.0859\n",
      "Epoch 79/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 93541.3438\n",
      "Epoch 80/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 93291.8125\n",
      "Epoch 81/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 93082.4531\n",
      "Epoch 82/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 92902.9141\n",
      "Epoch 83/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 92753.8828\n",
      "Epoch 84/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 92631.3047\n",
      "Epoch 85/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 92528.5000\n",
      "Epoch 86/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 92444.7578\n",
      "Epoch 87/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 92375.3750\n",
      "Epoch 88/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 92317.8438\n",
      "Epoch 89/200\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 92270.4844\n",
      "Epoch 90/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 90614.3125\n",
      "Epoch 91/200\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 64181.4609\n",
      "Epoch 92/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 55542.8750\n",
      "Epoch 93/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 53812.9297\n",
      "Epoch 94/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 52262.8789\n",
      "Epoch 95/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 50582.4844\n",
      "Epoch 96/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 49281.4062\n",
      "Epoch 97/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 48264.7422\n",
      "Epoch 98/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 47115.3711\n",
      "Epoch 99/200\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 46068.1250\n",
      "Epoch 100/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 45331.2539\n",
      "Epoch 101/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 44847.5586\n",
      "Epoch 102/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 43640.2812\n",
      "Epoch 103/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 43004.9375\n",
      "Epoch 104/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 42408.4180\n",
      "Epoch 105/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 41722.3789\n",
      "Epoch 106/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 41324.8008\n",
      "Epoch 107/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 40589.5352\n",
      "Epoch 108/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 40310.0742\n",
      "Epoch 109/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 40003.7031\n",
      "Epoch 110/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 39337.3906\n",
      "Epoch 111/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 39003.2500\n",
      "Epoch 112/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 38253.8828\n",
      "Epoch 113/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 37836.6211\n",
      "Epoch 114/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 37308.6016\n",
      "Epoch 115/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 36826.4531\n",
      "Epoch 116/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 36385.1016\n",
      "Epoch 117/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 35902.1055\n",
      "Epoch 118/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 35405.5664\n",
      "Epoch 119/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 35020.3125\n",
      "Epoch 120/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 34454.8438\n",
      "Epoch 121/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 33964.6680\n",
      "Epoch 122/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 33706.8711\n",
      "Epoch 123/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 33068.6016\n",
      "Epoch 124/200\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 32886.9727\n",
      "Epoch 125/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 32310.4043\n",
      "Epoch 126/200\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 31949.1016\n",
      "Epoch 127/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 31534.0098\n",
      "Epoch 128/200\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 31188.0605\n",
      "Epoch 129/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 30781.8066\n",
      "Epoch 130/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 30464.6035\n",
      "Epoch 131/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 30142.7012\n",
      "Epoch 132/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 29660.4102\n",
      "Epoch 133/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 29391.1445\n",
      "Epoch 134/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 29052.0215\n",
      "Epoch 135/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 28661.0039\n",
      "Epoch 136/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 28410.2656\n",
      "Epoch 137/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 28104.5742\n",
      "Epoch 138/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 27927.2012\n",
      "Epoch 139/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 27554.4141\n",
      "Epoch 140/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 27387.6543\n",
      "Epoch 141/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 27035.4707\n",
      "Epoch 142/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 26697.4668\n",
      "Epoch 143/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 26444.3906\n",
      "Epoch 144/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 26166.5898\n",
      "Epoch 145/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 25856.7695\n",
      "Epoch 146/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 25588.4375\n",
      "Epoch 147/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 25472.8555\n",
      "Epoch 148/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 25105.0723\n",
      "Epoch 149/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 24881.9355\n",
      "Epoch 150/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 24620.6582\n",
      "Epoch 151/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 24270.2051\n",
      "Epoch 152/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 24107.7695\n",
      "Epoch 153/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 23878.1543\n",
      "Epoch 154/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 23618.0117\n",
      "Epoch 155/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 23448.8477\n",
      "Epoch 156/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 23251.4590\n",
      "Epoch 157/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 22919.1191\n",
      "Epoch 158/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 22717.5293\n",
      "Epoch 159/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 22609.5586\n",
      "Epoch 160/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 22329.5098\n",
      "Epoch 161/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 22061.1953\n",
      "Epoch 162/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 21793.9199\n",
      "Epoch 163/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 21623.8867\n",
      "Epoch 164/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 21454.5293\n",
      "Epoch 165/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 21260.4805\n",
      "Epoch 166/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 20974.6562\n",
      "Epoch 167/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 20747.2500\n",
      "Epoch 168/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 20485.3633\n",
      "Epoch 169/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 20289.3008\n",
      "Epoch 170/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 20072.3438\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393/393 [==============================] - 1s 2ms/step - loss: 19858.4395\n",
      "Epoch 172/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 19710.1621\n",
      "Epoch 173/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 19512.5664\n",
      "Epoch 174/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 19239.1191\n",
      "Epoch 175/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 19032.7109\n",
      "Epoch 176/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 18826.9883\n",
      "Epoch 177/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 18542.6836\n",
      "Epoch 178/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 18414.1836\n",
      "Epoch 179/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 18251.1621\n",
      "Epoch 180/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 17978.8789\n",
      "Epoch 181/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 17743.1211\n",
      "Epoch 182/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 17630.5352\n",
      "Epoch 183/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 17394.0820\n",
      "Epoch 184/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 17168.1875\n",
      "Epoch 185/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 17065.4668\n",
      "Epoch 186/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 16816.8438\n",
      "Epoch 187/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 16592.9785\n",
      "Epoch 188/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 16390.1172\n",
      "Epoch 189/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 16189.3496\n",
      "Epoch 190/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 15972.4443\n",
      "Epoch 191/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 15808.8164\n",
      "Epoch 192/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 15580.1602\n",
      "Epoch 193/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 15376.9854\n",
      "Epoch 194/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 15159.3389\n",
      "Epoch 195/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 14968.3555\n",
      "Epoch 196/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 14724.4502\n",
      "Epoch 197/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 14593.0127\n",
      "Epoch 198/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 14317.4658\n",
      "Epoch 199/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 14126.9170\n",
      "Epoch 200/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 13891.2354\n",
      "97/97 [==============================] - 0s 956us/step\n",
      "R^squared: 0.8522399182161529\n",
      "MSE:  13493.418894811228\n",
      "RMSE:  116.1611763663369\n",
      "MAE: 74.72318826160819\n",
      "1/1 [==============================] - 0s 95ms/step\n"
     ]
    }
   ],
   "source": [
    "model_outputs_nn = {}\n",
    "sample_predicted_nn={}\n",
    "\n",
    "for i, (key, model) in enumerate(models.items()):\n",
    "    if key == 'MLP':\n",
    "        model, score, mse, rmse, mae=training_model(X_train_scaled, X_test_scaled, y_train, y_test ,model)\n",
    "        model_outputs_nn[key] = {'R-squared': score, 'MSE': mse, 'RMSE': rmse, 'MAE': mae}\n",
    "        sample_data = scaler.transform(sample2)\n",
    "        sample_predicted_nn[key]=model.predict(sample_data)\n",
    "    else:\n",
    "        model, score, mse, rmse, mae =nn_models(X_train_scaled, X_test_scaled, y_train, y_test, model, epoch_num=200, batch_size=16)\n",
    "        model_outputs_nn[key] = {'R-squared': score, 'MSE': mse, 'RMSE': rmse, 'MAE': mae}\n",
    "        sample_predicted_nn[key]=model.predict(sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0904a00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLP</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>RNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>0.996827</td>\n",
       "      <td>0.988807</td>\n",
       "      <td>0.852240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>289.755888</td>\n",
       "      <td>1022.117177</td>\n",
       "      <td>13493.418895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>17.022217</td>\n",
       "      <td>31.970567</td>\n",
       "      <td>116.161176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>4.494267</td>\n",
       "      <td>9.041862</td>\n",
       "      <td>74.723188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  MLP         LSTM           RNN\n",
       "R-squared    0.996827     0.988807      0.852240\n",
       "MSE        289.755888  1022.117177  13493.418895\n",
       "RMSE        17.022217    31.970567    116.161176\n",
       "MAE          4.494267     9.041862     74.723188"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_outputs_nn = pd.DataFrame(model_outputs_nn)\n",
    "model_outputs_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ec27051c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MLP': array([ 114.02331799,  203.77214282, 1036.34164395, 1307.08928   ,\n",
       "         673.25235903,  250.00021774,  305.31845559,  186.06101643,\n",
       "         272.51099766,  304.59565055,  128.30556064]),\n",
       " 'LSTM': array([[ 33.764343],\n",
       "        [ 13.440798],\n",
       "        [319.10892 ],\n",
       "        [509.40875 ],\n",
       "        [319.83093 ],\n",
       "        [421.9389  ],\n",
       "        [348.9947  ],\n",
       "        [379.78265 ],\n",
       "        [429.5772  ],\n",
       "        [395.2431  ],\n",
       "        [ 35.919037]], dtype=float32),\n",
       " 'RNN': array([[-579.7477 ],\n",
       "        [-583.7301 ],\n",
       "        [ 773.9526 ],\n",
       "        [ 773.9526 ],\n",
       "        [ 773.9526 ],\n",
       "        [ 775.93274],\n",
       "        [ 773.9526 ],\n",
       "        [ 872.5875 ],\n",
       "        [ 788.4404 ],\n",
       "        [ 841.5123 ],\n",
       "        [-677.8798 ]], dtype=float32)}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_predicted_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d7b607eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_predicted_nn['LSTM'] = sample_predicted_nn['LSTM'].flatten()\n",
    "sample_predicted_nn['RNN'] = sample_predicted_nn['RNN'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "968fc700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prıce</th>\n",
       "      <th>MLP</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>RNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116.47</td>\n",
       "      <td>114.023318</td>\n",
       "      <td>33.764343</td>\n",
       "      <td>-579.747681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>203.02</td>\n",
       "      <td>203.772143</td>\n",
       "      <td>13.440798</td>\n",
       "      <td>-583.730103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1038.15</td>\n",
       "      <td>1036.341644</td>\n",
       "      <td>319.108917</td>\n",
       "      <td>773.952576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1307.82</td>\n",
       "      <td>1307.089280</td>\n",
       "      <td>509.408752</td>\n",
       "      <td>773.952576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>674.56</td>\n",
       "      <td>673.252359</td>\n",
       "      <td>319.830933</td>\n",
       "      <td>773.952576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>243.50</td>\n",
       "      <td>250.000218</td>\n",
       "      <td>421.938904</td>\n",
       "      <td>775.932739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>303.87</td>\n",
       "      <td>305.318456</td>\n",
       "      <td>348.994690</td>\n",
       "      <td>773.952576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>184.08</td>\n",
       "      <td>186.061016</td>\n",
       "      <td>379.782654</td>\n",
       "      <td>872.587524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>275.78</td>\n",
       "      <td>272.510998</td>\n",
       "      <td>429.577209</td>\n",
       "      <td>788.440430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>327.88</td>\n",
       "      <td>304.595651</td>\n",
       "      <td>395.243103</td>\n",
       "      <td>841.512329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>122.03</td>\n",
       "      <td>128.305561</td>\n",
       "      <td>35.919037</td>\n",
       "      <td>-677.879822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prıce          MLP        LSTM         RNN\n",
       "0    116.47   114.023318   33.764343 -579.747681\n",
       "1    203.02   203.772143   13.440798 -583.730103\n",
       "2   1038.15  1036.341644  319.108917  773.952576\n",
       "3   1307.82  1307.089280  509.408752  773.952576\n",
       "4    674.56   673.252359  319.830933  773.952576\n",
       "5    243.50   250.000218  421.938904  775.932739\n",
       "6    303.87   305.318456  348.994690  773.952576\n",
       "7    184.08   186.061016  379.782654  872.587524\n",
       "8    275.78   272.510998  429.577209  788.440430\n",
       "9    327.88   304.595651  395.243103  841.512329\n",
       "10   122.03   128.305561   35.919037 -677.879822"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_predicted_nn = pd.DataFrame(sample_predicted_nn)\n",
    "real_pred_nn=pd.concat([a[['prıce']],sample_predicted_nn], axis=1)\n",
    "real_pred_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1692a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
