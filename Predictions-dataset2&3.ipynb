{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "097c81af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook model_functions.ipynb to script\n",
      "[NbConvertApp] Writing 2362 bytes to model_functions.py\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score,RandomizedSearchCV,RepeatedKFold\n",
    "from sklearn.linear_model import Ridge,Lasso, LassoCV,LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from model_functions import label_encoding,training_model,nn_models\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset=pd.read_excel(\"dataset.xlsx\")\n",
    "a=pd.read_excel(\"sample2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "729e4f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoding(dataset, a, 'Destination')\n",
    "label_encoding(dataset, a, 'Origin')\n",
    "label_encoding(dataset, a, 'To Area')\n",
    "label_encoding(dataset, a, 'day_name')\n",
    "label_encoding(dataset, a, 'flight_month')\n",
    "\n",
    "label_encoding(dataset, a, 'season')\n",
    "label_encoding(dataset, a, 'Netto Currency')\n",
    "label_encoding(dataset, a, 'Flight Code')\n",
    "\n",
    "label_encoding(dataset, a, 'Airline Company')\n",
    "label_encoding(dataset, a, 'Flight Date')\n",
    "\n",
    "label_encoding(dataset, a, 'dpt')\n",
    "label_encoding(dataset, a, 'dpt1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc6c7141",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9376 entries, 0 to 9375\n",
      "Data columns (total 27 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Destination      9376 non-null   int64  \n",
      " 1   Origin           9376 non-null   int64  \n",
      " 2   To Area          9376 non-null   int64  \n",
      " 3   Flight Date      9376 non-null   int64  \n",
      " 4   day_name         9376 non-null   int64  \n",
      " 5   flight_month     9376 non-null   int64  \n",
      " 6   season           9376 non-null   int64  \n",
      " 7   year             9376 non-null   int64  \n",
      " 8   Flight Code      9376 non-null   int64  \n",
      " 9   Days             9376 non-null   int64  \n",
      " 10  Airline Company  9376 non-null   int64  \n",
      " 11  dpt              9376 non-null   int64  \n",
      " 12  Block            9376 non-null   int64  \n",
      " 13  Sold             9376 non-null   int64  \n",
      " 14  Left             9376 non-null   int64  \n",
      " 15  Occ.(%)          9376 non-null   int64  \n",
      " 16  dpt1             9376 non-null   int64  \n",
      " 17  Block1           9376 non-null   int64  \n",
      " 18  Sold1            9376 non-null   int64  \n",
      " 19  Left1            9376 non-null   int64  \n",
      " 20  Occ.(%)1         9376 non-null   int64  \n",
      " 21  Occ.             9376 non-null   float64\n",
      " 22  Netto            9376 non-null   float64\n",
      " 23  Netto Currency   9376 non-null   int64  \n",
      " 24  Profit           9265 non-null   float64\n",
      " 25  prıce            9376 non-null   float64\n",
      " 26  day_convert      9376 non-null   object \n",
      "dtypes: float64(4), int64(22), object(1)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aff33153",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11 entries, 0 to 10\n",
      "Data columns (total 26 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Destination      11 non-null     int64  \n",
      " 1   Origin           11 non-null     int64  \n",
      " 2   To Area          11 non-null     int64  \n",
      " 3   Flight Date      11 non-null     int64  \n",
      " 4   day_name         11 non-null     int64  \n",
      " 5   flight_month     11 non-null     int64  \n",
      " 6   season           11 non-null     int64  \n",
      " 7   year             11 non-null     int64  \n",
      " 8   Flight Code      11 non-null     int64  \n",
      " 9   Days             11 non-null     int64  \n",
      " 10  Airline Company  11 non-null     int64  \n",
      " 11  dpt              11 non-null     int64  \n",
      " 12  Block            11 non-null     int64  \n",
      " 13  Sold             11 non-null     int64  \n",
      " 14  Left             11 non-null     int64  \n",
      " 15  Occ.(%)          11 non-null     int64  \n",
      " 16  dpt1             11 non-null     int64  \n",
      " 17  Block1           11 non-null     int64  \n",
      " 18  Sold1            11 non-null     int64  \n",
      " 19  Left1            11 non-null     int64  \n",
      " 20  Occ.(%)1         11 non-null     int64  \n",
      " 21  Occ.             11 non-null     float64\n",
      " 22  Netto            11 non-null     float64\n",
      " 23  Netto Currency   11 non-null     int64  \n",
      " 24  Profit           11 non-null     float64\n",
      " 25  prıce            11 non-null     float64\n",
      "dtypes: float64(4), int64(22)\n",
      "memory usage: 2.4 KB\n"
     ]
    }
   ],
   "source": [
    "a.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6208998d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(['day_convert'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a09eeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Profit\"]=dataset[\"Profit\"].fillna(dataset[\"Profit\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03b83023",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(['Occ.'], axis=1) # independent variables\n",
    "y = dataset[['Occ.']]  # dependent variables\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.values.ravel(), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "465b7c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination</th>\n",
       "      <th>Origin</th>\n",
       "      <th>To Area</th>\n",
       "      <th>Flight Date</th>\n",
       "      <th>day_name</th>\n",
       "      <th>flight_month</th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>Flight Code</th>\n",
       "      <th>Days</th>\n",
       "      <th>...</th>\n",
       "      <th>Occ.(%)</th>\n",
       "      <th>dpt1</th>\n",
       "      <th>Block1</th>\n",
       "      <th>Sold1</th>\n",
       "      <th>Left1</th>\n",
       "      <th>Occ.(%)1</th>\n",
       "      <th>Netto</th>\n",
       "      <th>Netto Currency</th>\n",
       "      <th>Profit</th>\n",
       "      <th>prıce</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>220</td>\n",
       "      <td>151</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>177.00</td>\n",
       "      <td>0</td>\n",
       "      <td>61.73</td>\n",
       "      <td>238.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>174.00</td>\n",
       "      <td>0</td>\n",
       "      <td>229.11</td>\n",
       "      <td>174.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>220</td>\n",
       "      <td>181</td>\n",
       "      <td>39</td>\n",
       "      <td>82</td>\n",
       "      <td>253.00</td>\n",
       "      <td>0</td>\n",
       "      <td>58.35</td>\n",
       "      <td>311.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>220</td>\n",
       "      <td>217</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>236.00</td>\n",
       "      <td>0</td>\n",
       "      <td>229.11</td>\n",
       "      <td>236.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>251.00</td>\n",
       "      <td>0</td>\n",
       "      <td>-50.69</td>\n",
       "      <td>200.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9371</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>496</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>152</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>12</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>377.18</td>\n",
       "      <td>0</td>\n",
       "      <td>420.95</td>\n",
       "      <td>798.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9372</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>496</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>149</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>26</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>343.18</td>\n",
       "      <td>0</td>\n",
       "      <td>398.44</td>\n",
       "      <td>741.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9373</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>497</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>151</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>47</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>370.00</td>\n",
       "      <td>1</td>\n",
       "      <td>512.82</td>\n",
       "      <td>882.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9374</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>497</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>148</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>188</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>377.18</td>\n",
       "      <td>0</td>\n",
       "      <td>467.51</td>\n",
       "      <td>844.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9375</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>497</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>148</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>188</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>703.18</td>\n",
       "      <td>0</td>\n",
       "      <td>361.37</td>\n",
       "      <td>1064.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9376 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Destination  Origin  To Area  Flight Date  day_name  flight_month  \\\n",
       "0               0       0        0            0         0             0   \n",
       "1               0       0        0            1         0             0   \n",
       "2               0       1        0            0         0             0   \n",
       "3               0       1        0            2         1             0   \n",
       "4               0       1        0            3         2             1   \n",
       "...           ...     ...      ...          ...       ...           ...   \n",
       "9371            0       5        0          496         6             9   \n",
       "9372            0       5        0          496         6             9   \n",
       "9373            0       5        0          497         2             9   \n",
       "9374            0       5        0          497         2             9   \n",
       "9375            0       5        0          497         2             9   \n",
       "\n",
       "      season  year  Flight Code  Days  ...  Occ.(%)  dpt1  Block1  Sold1  \\\n",
       "0          0  2020            0     4  ...       95     0     220    151   \n",
       "1          0  2020            0     4  ...        0     0     220    220   \n",
       "2          0  2020            1     4  ...       98     0     220    181   \n",
       "3          0  2020            1     5  ...        0     0     220    217   \n",
       "4          1  2020            2     7  ...       99     0     220      1   \n",
       "...      ...   ...          ...   ...  ...      ...   ...     ...    ...   \n",
       "9371       3  2022          152     6  ...      100    12      65     65   \n",
       "9372       3  2022          149     6  ...      100    26      46     46   \n",
       "9373       3  2022          151     7  ...      100    47      34     34   \n",
       "9374       3  2022          148     7  ...      100   188      54     54   \n",
       "9375       3  2022          148     7  ...      100   188       5      5   \n",
       "\n",
       "      Left1  Occ.(%)1   Netto  Netto Currency  Profit    prıce  \n",
       "0        69        69  177.00               0   61.73   238.73  \n",
       "1         0       100  174.00               0  229.11   174.00  \n",
       "2        39        82  253.00               0   58.35   311.35  \n",
       "3         3        99  236.00               0  229.11   236.00  \n",
       "4       219         0  251.00               0  -50.69   200.31  \n",
       "...     ...       ...     ...             ...     ...      ...  \n",
       "9371      0       100  377.18               0  420.95   798.13  \n",
       "9372      0       100  343.18               0  398.44   741.62  \n",
       "9373      0       100  370.00               1  512.82   882.82  \n",
       "9374      0       100  377.18               0  467.51   844.69  \n",
       "9375      0       100  703.18               0  361.37  1064.55  \n",
       "\n",
       "[9376 rows x 25 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6a5c22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occ.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9371</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9372</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9373</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9374</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9375</th>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9376 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Occ.\n",
       "0      95.45\n",
       "1       0.00\n",
       "2      97.73\n",
       "3       0.00\n",
       "4      99.09\n",
       "...      ...\n",
       "9371  100.00\n",
       "9372  100.00\n",
       "9373  100.00\n",
       "9374  100.00\n",
       "9375  100.00\n",
       "\n",
       "[9376 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2dfc19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 23, max_depth = 30,min_samples_split=5,random_state = 42)\n",
    "DT_Regressor = tree.DecisionTreeRegressor()\n",
    "ridge = Ridge(alpha=1.0)\n",
    "lasso_cv = LassoCV(alphas = None, cv = 10, max_iter = 100000, normalize = True)\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98730512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor()\n",
    "\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.0001,0.001, 0.01, 0.1, 1] ,\n",
    "    \"max_depth\": range(3,21,3),\n",
    "    \"gamma\": [i/10.0 for i in range(0,5)],\n",
    "    \"colsample_bytree\": [i/10.0 for i in range(3,10)],\n",
    "    \"reg_alpha\": [1e-5, 1e-2, 0.1, 1, 10, 100],\n",
    "    \"reg_lambda\": [1e-5, 1e-2, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "xgb_cv = RandomizedSearchCV(xgb, param_grid, n_iter = 100, refit='recall',\n",
    "         scoring='neg_mean_squared_error', cv = 5, verbose=2, random_state=42, n_jobs = -1) \n",
    "xgb_cv.fit(X_train, y_train)\n",
    "xgb_reg = XGBRegressor(**xgb_cv.best_params_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "721badfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = { 'Random forest': rf,'Decision tree': DT_Regressor,'Ridge regression': ridge,\n",
    "          'Lasso regression': lasso_cv,'Linear regression': lr,'XGBOOST': xgb_reg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7af61466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination</th>\n",
       "      <th>Origin</th>\n",
       "      <th>To Area</th>\n",
       "      <th>Flight Date</th>\n",
       "      <th>day_name</th>\n",
       "      <th>flight_month</th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>Flight Code</th>\n",
       "      <th>Days</th>\n",
       "      <th>...</th>\n",
       "      <th>Occ.(%)</th>\n",
       "      <th>dpt1</th>\n",
       "      <th>Block1</th>\n",
       "      <th>Sold1</th>\n",
       "      <th>Left1</th>\n",
       "      <th>Occ.(%)1</th>\n",
       "      <th>Netto</th>\n",
       "      <th>Netto Currency</th>\n",
       "      <th>Profit</th>\n",
       "      <th>prıce</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>325</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>148</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>28</td>\n",
       "      <td>220</td>\n",
       "      <td>212</td>\n",
       "      <td>8</td>\n",
       "      <td>96</td>\n",
       "      <td>149.00</td>\n",
       "      <td>1</td>\n",
       "      <td>-32.53</td>\n",
       "      <td>116.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>481</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>127</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>71</td>\n",
       "      <td>170</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>246.00</td>\n",
       "      <td>0</td>\n",
       "      <td>-42.98</td>\n",
       "      <td>203.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>703</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2022</td>\n",
       "      <td>152</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>69</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>475.82</td>\n",
       "      <td>0</td>\n",
       "      <td>562.33</td>\n",
       "      <td>1038.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>552</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>660.36</td>\n",
       "      <td>0</td>\n",
       "      <td>647.46</td>\n",
       "      <td>1307.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>210</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>26</td>\n",
       "      <td>163</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>356.36</td>\n",
       "      <td>0</td>\n",
       "      <td>318.20</td>\n",
       "      <td>674.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>561</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>64</td>\n",
       "      <td>478</td>\n",
       "      <td>8</td>\n",
       "      <td>470</td>\n",
       "      <td>2</td>\n",
       "      <td>162.00</td>\n",
       "      <td>0</td>\n",
       "      <td>81.50</td>\n",
       "      <td>243.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>560</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>71</td>\n",
       "      <td>474</td>\n",
       "      <td>0</td>\n",
       "      <td>474</td>\n",
       "      <td>0</td>\n",
       "      <td>150.00</td>\n",
       "      <td>0</td>\n",
       "      <td>153.87</td>\n",
       "      <td>303.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>105</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>156</td>\n",
       "      <td>328</td>\n",
       "      <td>322</td>\n",
       "      <td>6</td>\n",
       "      <td>98</td>\n",
       "      <td>162.00</td>\n",
       "      <td>1</td>\n",
       "      <td>22.08</td>\n",
       "      <td>184.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>507</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>148</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>96</td>\n",
       "      <td>188</td>\n",
       "      <td>110</td>\n",
       "      <td>82</td>\n",
       "      <td>28</td>\n",
       "      <td>75</td>\n",
       "      <td>200.00</td>\n",
       "      <td>0</td>\n",
       "      <td>75.78</td>\n",
       "      <td>275.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>532</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>110</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>165</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>259.00</td>\n",
       "      <td>0</td>\n",
       "      <td>68.88</td>\n",
       "      <td>327.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>405</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>32</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>197.00</td>\n",
       "      <td>0</td>\n",
       "      <td>-74.97</td>\n",
       "      <td>122.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Destination  Origin  To Area  Flight Date  day_name  flight_month  season  \\\n",
       "0             0      27        0          325         5             6       2   \n",
       "1             0      28        0          481         4             8       3   \n",
       "2             0      29        0          703         2            12       4   \n",
       "3             0      30        0          552         6             6       2   \n",
       "4             0      31        0          210         1             5       2   \n",
       "5             0      32        0          561         3             4       3   \n",
       "6             0      33        0          560         2             5       2   \n",
       "7             0      34        0          490         2             5       2   \n",
       "8             0      35        0          507         5             9       3   \n",
       "9             0      36        0          532         2             9       3   \n",
       "10            0      37        0          405         3             4       3   \n",
       "\n",
       "    year  Flight Code  Days  ...  Occ.(%)  dpt1  Block1  Sold1  Left1  \\\n",
       "0   2021          148     3  ...       65    28     220    212      8   \n",
       "1   2022          127     2  ...       71   170     189    189      0   \n",
       "2   2022          152     7  ...      100    69      58     58      0   \n",
       "3   2022           31     6  ...      100    23      14     14      0   \n",
       "4   2021            9     5  ...      100    26     163    163      0   \n",
       "5   2022          122     1  ...       99    64     478      8    470   \n",
       "6   2022          128     7  ...      100    71     474      0    474   \n",
       "7   2022          105     7  ...       99   156     328    322      6   \n",
       "8   2022          148     3  ...       96   188     110     82     28   \n",
       "9   2022          110     7  ...       23   165     235    235      0   \n",
       "10  2021           88     1  ...       53    32     220    220      0   \n",
       "\n",
       "    Occ.(%)1   Netto  Netto Currency  Profit    prıce  \n",
       "0         96  149.00               1  -32.53   116.47  \n",
       "1        100  246.00               0  -42.98   203.02  \n",
       "2        100  475.82               0  562.33  1038.15  \n",
       "3        100  660.36               0  647.46  1307.82  \n",
       "4        100  356.36               0  318.20   674.56  \n",
       "5          2  162.00               0   81.50   243.50  \n",
       "6          0  150.00               0  153.87   303.87  \n",
       "7         98  162.00               1   22.08   184.08  \n",
       "8         75  200.00               0   75.78   275.78  \n",
       "9        100  259.00               0   68.88   327.88  \n",
       "10       100  197.00               0  -74.97   122.03  \n",
       "\n",
       "[11 rows x 25 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample2 = a.drop(['Occ.'], axis=1) \n",
    "sample2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2f9fc10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^squared: 0.9999412137945068\n",
      "MSE:  0.019776159642935023\n",
      "RMSE:  0.14062773425940925\n",
      "MAE: 0.042945902476942285\n",
      "R^squared: 0.9999162064913039\n",
      "MSE:  0.028188820678513818\n",
      "RMSE:  0.1678952669925922\n",
      "MAE: 0.0454474959612295\n",
      "R^squared: 0.9999321011434565\n",
      "MSE:  0.022841729880548008\n",
      "RMSE:  0.15113480697889553\n",
      "MAE: 0.07418374294832374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\90541\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^squared: 0.9999310533141627\n",
      "MSE:  0.023194228212768238\n",
      "RMSE:  0.15229651411889977\n",
      "MAE: 0.07777834358277923\n",
      "R^squared: 0.9999320917574066\n",
      "MSE:  0.022844887424396373\n",
      "RMSE:  0.1511452527352294\n",
      "MAE: 0.07423272453192054\n",
      "R^squared: 0.9999322011204053\n",
      "MSE:  0.022808096818468584\n",
      "RMSE:  0.15102349757063827\n",
      "MAE: 0.04928218888711665\n"
     ]
    }
   ],
   "source": [
    "model_outputs = {}\n",
    "sample_predicted={}\n",
    "\n",
    "for i, (key, model) in enumerate(models.items()):\n",
    "    model, score, mse, rmse, mae = training_model(X_train, X_test, y_train, y_test, model=model)\n",
    "    model_outputs[key] = {'R-squared': score, 'MSE': mse, 'RMSE': rmse, 'MAE': mae}\n",
    "    sample_predicted[key]=model.predict(sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3723913a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random forest</th>\n",
       "      <th>Decision tree</th>\n",
       "      <th>Ridge regression</th>\n",
       "      <th>Lasso regression</th>\n",
       "      <th>Linear regression</th>\n",
       "      <th>XGBOOST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.999916</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>0.999931</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>0.999932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.019776</td>\n",
       "      <td>0.028189</td>\n",
       "      <td>0.022842</td>\n",
       "      <td>0.023194</td>\n",
       "      <td>0.022845</td>\n",
       "      <td>0.022808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.140628</td>\n",
       "      <td>0.167895</td>\n",
       "      <td>0.151135</td>\n",
       "      <td>0.152297</td>\n",
       "      <td>0.151145</td>\n",
       "      <td>0.151023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.042946</td>\n",
       "      <td>0.045447</td>\n",
       "      <td>0.074184</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>0.074233</td>\n",
       "      <td>0.049282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Random forest  Decision tree  Ridge regression  Lasso regression  \\\n",
       "R-squared       0.999941       0.999916          0.999932          0.999931   \n",
       "MSE             0.019776       0.028189          0.022842          0.023194   \n",
       "RMSE            0.140628       0.167895          0.151135          0.152297   \n",
       "MAE             0.042946       0.045447          0.074184          0.077778   \n",
       "\n",
       "           Linear regression   XGBOOST  \n",
       "R-squared           0.999932  0.999932  \n",
       "MSE                 0.022845  0.022808  \n",
       "RMSE                0.151145  0.151023  \n",
       "MAE                 0.074233  0.049282  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_outputs = pd.DataFrame(model_outputs)\n",
    "model_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21ec6686",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_predicted = pd.DataFrame(sample_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8ed3402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occ.</th>\n",
       "      <th>Random forest</th>\n",
       "      <th>Decision tree</th>\n",
       "      <th>Ridge regression</th>\n",
       "      <th>Lasso regression</th>\n",
       "      <th>Linear regression</th>\n",
       "      <th>XGBOOST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.45</td>\n",
       "      <td>64.955170</td>\n",
       "      <td>65.15</td>\n",
       "      <td>64.986269</td>\n",
       "      <td>65.020637</td>\n",
       "      <td>64.984408</td>\n",
       "      <td>64.696053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.90</td>\n",
       "      <td>70.867657</td>\n",
       "      <td>70.91</td>\n",
       "      <td>70.992115</td>\n",
       "      <td>71.015619</td>\n",
       "      <td>70.989913</td>\n",
       "      <td>71.365166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.985898</td>\n",
       "      <td>99.986159</td>\n",
       "      <td>99.983943</td>\n",
       "      <td>99.996536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.965786</td>\n",
       "      <td>99.986159</td>\n",
       "      <td>99.963075</td>\n",
       "      <td>99.997612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.00</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00</td>\n",
       "      <td>99.940899</td>\n",
       "      <td>99.985082</td>\n",
       "      <td>99.938278</td>\n",
       "      <td>99.996582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>99.39</td>\n",
       "      <td>99.372941</td>\n",
       "      <td>99.39</td>\n",
       "      <td>98.902796</td>\n",
       "      <td>98.987175</td>\n",
       "      <td>98.901536</td>\n",
       "      <td>99.317116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>99.58</td>\n",
       "      <td>99.586739</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.910810</td>\n",
       "      <td>99.986159</td>\n",
       "      <td>99.909278</td>\n",
       "      <td>99.578796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>99.39</td>\n",
       "      <td>99.370217</td>\n",
       "      <td>99.39</td>\n",
       "      <td>98.972141</td>\n",
       "      <td>98.987175</td>\n",
       "      <td>98.969371</td>\n",
       "      <td>99.107887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>95.80</td>\n",
       "      <td>96.003873</td>\n",
       "      <td>96.30</td>\n",
       "      <td>95.984824</td>\n",
       "      <td>95.990222</td>\n",
       "      <td>95.982059</td>\n",
       "      <td>96.082130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23.40</td>\n",
       "      <td>22.879308</td>\n",
       "      <td>22.73</td>\n",
       "      <td>23.005094</td>\n",
       "      <td>23.064379</td>\n",
       "      <td>23.002448</td>\n",
       "      <td>23.156067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>53.05</td>\n",
       "      <td>52.659529</td>\n",
       "      <td>52.73</td>\n",
       "      <td>52.980644</td>\n",
       "      <td>53.032827</td>\n",
       "      <td>52.977806</td>\n",
       "      <td>53.030064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Occ.  Random forest  Decision tree  Ridge regression  Lasso regression  \\\n",
       "0    65.45      64.955170          65.15         64.986269         65.020637   \n",
       "1    70.90      70.867657          70.91         70.992115         71.015619   \n",
       "2   100.00     100.000000         100.00         99.985898         99.986159   \n",
       "3   100.00     100.000000         100.00         99.965786         99.986159   \n",
       "4   100.00     100.000000         100.00         99.940899         99.985082   \n",
       "5    99.39      99.372941          99.39         98.902796         98.987175   \n",
       "6    99.58      99.586739          99.58         99.910810         99.986159   \n",
       "7    99.39      99.370217          99.39         98.972141         98.987175   \n",
       "8    95.80      96.003873          96.30         95.984824         95.990222   \n",
       "9    23.40      22.879308          22.73         23.005094         23.064379   \n",
       "10   53.05      52.659529          52.73         52.980644         53.032827   \n",
       "\n",
       "    Linear regression    XGBOOST  \n",
       "0           64.984408  64.696053  \n",
       "1           70.989913  71.365166  \n",
       "2           99.983943  99.996536  \n",
       "3           99.963075  99.997612  \n",
       "4           99.938278  99.996582  \n",
       "5           98.901536  99.317116  \n",
       "6           99.909278  99.578796  \n",
       "7           98.969371  99.107887  \n",
       "8           95.982059  96.082130  \n",
       "9           23.002448  23.156067  \n",
       "10          52.977806  53.030064  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_pred=pd.concat([a[['Occ.']],sample_predicted], axis=1)\n",
    "real_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c263ccec",
   "metadata": {},
   "source": [
    "## mlp-lstm-rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db5cb196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from tensorflow.python.keras.layers import Dense, LSTM, RepeatVector, Flatten,SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "959827ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8878ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape (6281, 25)\n",
      "Test shape (3095, 25)\n"
     ]
    }
   ],
   "source": [
    "print('Train shape', X_train_scaled.shape)\n",
    "print('Test shape', X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "693ddaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input [samples, time steps, features] for LSTM\n",
    "X_train_items = np.reshape(X_train_scaled, (X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
    "X_test_items = np.reshape(X_test_scaled, (X_test_scaled.shape[0], X_test_scaled.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "247acefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(500, 50), max_iter=2000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a98966",
   "metadata": {},
   "source": [
    "training_model(X_train_scaled, X_test_scaled, y_train, y_test ,mlp)\n",
    "sample_data = scaler.transform(sample2)\n",
    "predictions = mlp.predict(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a13daef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "modellstm = Sequential()\n",
    "modellstm.add(LSTM(50, input_shape=(X_train_items.shape[1], 1)))\n",
    "modellstm.add(Dense(1))\n",
    "modellstm.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c35a116",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = Sequential()\n",
    "rnn.add(SimpleRNN(units=20, input_shape=(X_train_items.shape[1], X_train_items.shape[2])))\n",
    "rnn.add(Dense(1))\n",
    "rnn.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47a4e782",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = { 'MLP': mlp,'LSTM': modellstm,'RNN': rnn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15768299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^squared: 0.9998429885379043\n",
      "MSE:  0.05281993818327457\n",
      "RMSE:  0.22982588666917958\n",
      "MAE: 0.16153498938828023\n",
      "Epoch 1/200\n",
      "393/393 [==============================] - 19s 34ms/step - loss: 6411.5400\n",
      "Epoch 2/200\n",
      "393/393 [==============================] - 14s 36ms/step - loss: 3798.3123\n",
      "Epoch 3/200\n",
      "393/393 [==============================] - 13s 33ms/step - loss: 2247.0933\n",
      "Epoch 4/200\n",
      "393/393 [==============================] - 12s 32ms/step - loss: 1296.7391\n",
      "Epoch 5/200\n",
      "393/393 [==============================] - 12s 31ms/step - loss: 760.7768\n",
      "Epoch 6/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 492.1812\n",
      "Epoch 7/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 377.5273\n",
      "Epoch 8/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 338.0033\n",
      "Epoch 9/200\n",
      "393/393 [==============================] - 12s 31ms/step - loss: 327.6563\n",
      "Epoch 10/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 325.6842\n",
      "Epoch 11/200\n",
      "393/393 [==============================] - 12s 30ms/step - loss: 325.4366\n",
      "Epoch 12/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 325.4383\n",
      "Epoch 13/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 325.3705\n",
      "Epoch 14/200\n",
      "393/393 [==============================] - 13s 32ms/step - loss: 325.4669\n",
      "Epoch 15/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 325.4586\n",
      "Epoch 16/200\n",
      "393/393 [==============================] - 12s 29ms/step - loss: 325.4405\n",
      "Epoch 17/200\n",
      "393/393 [==============================] - 12s 30ms/step - loss: 325.4345\n",
      "Epoch 18/200\n",
      "393/393 [==============================] - 12s 30ms/step - loss: 325.5017\n",
      "Epoch 19/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 325.4234\n",
      "Epoch 20/200\n",
      "393/393 [==============================] - 13s 34ms/step - loss: 325.4907\n",
      "Epoch 21/200\n",
      "393/393 [==============================] - 13s 34ms/step - loss: 325.3120\n",
      "Epoch 22/200\n",
      "393/393 [==============================] - 12s 31ms/step - loss: 325.0723\n",
      "Epoch 23/200\n",
      "393/393 [==============================] - 12s 30ms/step - loss: 324.8686\n",
      "Epoch 24/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 324.5633\n",
      "Epoch 25/200\n",
      "393/393 [==============================] - 12s 30ms/step - loss: 325.5171\n",
      "Epoch 26/200\n",
      "393/393 [==============================] - 12s 29ms/step - loss: 322.6949\n",
      "Epoch 27/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 319.7035\n",
      "Epoch 28/200\n",
      "393/393 [==============================] - 12s 30ms/step - loss: 315.5641\n",
      "Epoch 29/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 313.3763\n",
      "Epoch 30/200\n",
      "393/393 [==============================] - 12s 29ms/step - loss: 309.5217\n",
      "Epoch 31/200\n",
      "393/393 [==============================] - 14s 35ms/step - loss: 302.6615\n",
      "Epoch 32/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 296.9192\n",
      "Epoch 33/200\n",
      "393/393 [==============================] - 14s 35ms/step - loss: 292.9976\n",
      "Epoch 34/200\n",
      "393/393 [==============================] - 11s 27ms/step - loss: 289.8133\n",
      "Epoch 35/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 287.7947\n",
      "Epoch 36/200\n",
      "393/393 [==============================] - 13s 32ms/step - loss: 275.1350\n",
      "Epoch 37/200\n",
      "393/393 [==============================] - 13s 33ms/step - loss: 261.9919\n",
      "Epoch 38/200\n",
      "393/393 [==============================] - 13s 32ms/step - loss: 227.5835\n",
      "Epoch 39/200\n",
      "393/393 [==============================] - 12s 30ms/step - loss: 201.3763\n",
      "Epoch 40/200\n",
      "393/393 [==============================] - 11s 27ms/step - loss: 146.7632\n",
      "Epoch 41/200\n",
      "393/393 [==============================] - 12s 29ms/step - loss: 113.4642\n",
      "Epoch 42/200\n",
      "393/393 [==============================] - 12s 30ms/step - loss: 78.0648\n",
      "Epoch 43/200\n",
      "393/393 [==============================] - 12s 30ms/step - loss: 75.9435\n",
      "Epoch 44/200\n",
      "393/393 [==============================] - 12s 31ms/step - loss: 64.7243\n",
      "Epoch 45/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 54.8771\n",
      "Epoch 46/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 37.2195\n",
      "Epoch 47/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 37.1476\n",
      "Epoch 48/200\n",
      "393/393 [==============================] - 12s 31ms/step - loss: 28.4079\n",
      "Epoch 49/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 20.6596\n",
      "Epoch 50/200\n",
      "393/393 [==============================] - 13s 34ms/step - loss: 16.4127\n",
      "Epoch 51/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 28.5641\n",
      "Epoch 52/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 10.5839\n",
      "Epoch 53/200\n",
      "393/393 [==============================] - 13s 32ms/step - loss: 7.7350\n",
      "Epoch 54/200\n",
      "393/393 [==============================] - 11s 27ms/step - loss: 13.8504\n",
      "Epoch 55/200\n",
      "393/393 [==============================] - 13s 33ms/step - loss: 5.4127\n",
      "Epoch 56/200\n",
      "393/393 [==============================] - 12s 29ms/step - loss: 4.9862\n",
      "Epoch 57/200\n",
      "393/393 [==============================] - 12s 30ms/step - loss: 3.2498\n",
      "Epoch 58/200\n",
      "393/393 [==============================] - 12s 30ms/step - loss: 3.8890\n",
      "Epoch 59/200\n",
      "393/393 [==============================] - 12s 31ms/step - loss: 3.4389\n",
      "Epoch 60/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 2.6663\n",
      "Epoch 61/200\n",
      "393/393 [==============================] - 12s 30ms/step - loss: 2.0901\n",
      "Epoch 62/200\n",
      "393/393 [==============================] - 12s 29ms/step - loss: 314.5055\n",
      "Epoch 63/200\n",
      "393/393 [==============================] - 12s 29ms/step - loss: 172.9526\n",
      "Epoch 64/200\n",
      "393/393 [==============================] - 12s 30ms/step - loss: 13.5920\n",
      "Epoch 65/200\n",
      "393/393 [==============================] - 12s 31ms/step - loss: 2.0220\n",
      "Epoch 66/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 1.4845\n",
      "Epoch 67/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 1.3341\n",
      "Epoch 68/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 1.0009\n",
      "Epoch 69/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 0.8637\n",
      "Epoch 70/200\n",
      "393/393 [==============================] - 12s 32ms/step - loss: 83.1181\n",
      "Epoch 71/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 115.9841\n",
      "Epoch 72/200\n",
      "393/393 [==============================] - 12s 31ms/step - loss: 9.6890\n",
      "Epoch 73/200\n",
      "393/393 [==============================] - 12s 30ms/step - loss: 4.7569\n",
      "Epoch 74/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 4.7595\n",
      "Epoch 75/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 3.6449\n",
      "Epoch 76/200\n",
      "393/393 [==============================] - 12s 31ms/step - loss: 1.7485\n",
      "Epoch 77/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 1.6512\n",
      "Epoch 78/200\n",
      "393/393 [==============================] - 12s 31ms/step - loss: 1.3679\n",
      "Epoch 79/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 1.3870\n",
      "Epoch 80/200\n",
      "393/393 [==============================] - 12s 32ms/step - loss: 0.7746\n",
      "Epoch 81/200\n",
      "393/393 [==============================] - 13s 33ms/step - loss: 9.2160\n",
      "Epoch 82/200\n",
      "393/393 [==============================] - 13s 33ms/step - loss: 12.2443\n",
      "Epoch 83/200\n",
      "393/393 [==============================] - 12s 31ms/step - loss: 0.7627\n",
      "Epoch 84/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 0.5779\n",
      "Epoch 85/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 0.4160\n",
      "Epoch 86/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 0.3450\n",
      "Epoch 87/200\n",
      "393/393 [==============================] - 12s 30ms/step - loss: 0.3219\n",
      "Epoch 88/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 0.3195\n",
      "Epoch 89/200\n",
      "393/393 [==============================] - 12s 32ms/step - loss: 0.2959\n",
      "Epoch 90/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 0.2955\n",
      "Epoch 91/200\n",
      "393/393 [==============================] - 12s 30ms/step - loss: 0.2289\n",
      "Epoch 92/200\n",
      "393/393 [==============================] - 12s 30ms/step - loss: 0.3126\n",
      "Epoch 93/200\n",
      "393/393 [==============================] - 12s 31ms/step - loss: 0.2898\n",
      "Epoch 94/200\n",
      "393/393 [==============================] - 12s 30ms/step - loss: 260.8556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/200\n",
      "393/393 [==============================] - 12s 32ms/step - loss: 320.4908\n",
      "Epoch 96/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 312.4555\n",
      "Epoch 97/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 305.1225\n",
      "Epoch 98/200\n",
      "393/393 [==============================] - 12s 31ms/step - loss: 301.4032\n",
      "Epoch 99/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 296.5451\n",
      "Epoch 100/200\n",
      "393/393 [==============================] - 12s 32ms/step - loss: 291.3379\n",
      "Epoch 101/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 283.5771\n",
      "Epoch 102/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 274.7753\n",
      "Epoch 103/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 266.2764\n",
      "Epoch 104/200\n",
      "393/393 [==============================] - 12s 31ms/step - loss: 259.7799\n",
      "Epoch 105/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 257.1606\n",
      "Epoch 106/200\n",
      "393/393 [==============================] - 12s 32ms/step - loss: 254.8206\n",
      "Epoch 107/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 249.6069\n",
      "Epoch 108/200\n",
      "393/393 [==============================] - 11s 27ms/step - loss: 245.1342\n",
      "Epoch 109/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 240.0889\n",
      "Epoch 110/200\n",
      "393/393 [==============================] - 13s 33ms/step - loss: 229.6533\n",
      "Epoch 111/200\n",
      "393/393 [==============================] - 12s 30ms/step - loss: 217.8811\n",
      "Epoch 112/200\n",
      "393/393 [==============================] - 12s 31ms/step - loss: 186.2892\n",
      "Epoch 113/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 82.9965\n",
      "Epoch 114/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 48.4273\n",
      "Epoch 115/200\n",
      "393/393 [==============================] - 13s 32ms/step - loss: 34.0150\n",
      "Epoch 116/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 18.9082\n",
      "Epoch 117/200\n",
      "393/393 [==============================] - 12s 30ms/step - loss: 11.8992\n",
      "Epoch 118/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 5.4358\n",
      "Epoch 119/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 3.6135\n",
      "Epoch 120/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 4.5830\n",
      "Epoch 121/200\n",
      "393/393 [==============================] - 12s 32ms/step - loss: 2.2612\n",
      "Epoch 122/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 1.4382\n",
      "Epoch 123/200\n",
      "393/393 [==============================] - 12s 31ms/step - loss: 1.1216\n",
      "Epoch 124/200\n",
      "393/393 [==============================] - 12s 30ms/step - loss: 39.4360\n",
      "Epoch 125/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 291.5508\n",
      "Epoch 126/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 203.7719\n",
      "Epoch 127/200\n",
      "393/393 [==============================] - 12s 29ms/step - loss: 66.3366\n",
      "Epoch 128/200\n",
      "393/393 [==============================] - 11s 27ms/step - loss: 20.8251\n",
      "Epoch 129/200\n",
      "393/393 [==============================] - 12s 30ms/step - loss: 10.3580\n",
      "Epoch 130/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 8.6547\n",
      "Epoch 131/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 8.4382\n",
      "Epoch 132/200\n",
      "393/393 [==============================] - 12s 31ms/step - loss: 3.5032\n",
      "Epoch 133/200\n",
      "393/393 [==============================] - 13s 33ms/step - loss: 2.8103\n",
      "Epoch 134/200\n",
      "393/393 [==============================] - 13s 32ms/step - loss: 2.5182\n",
      "Epoch 135/200\n",
      "393/393 [==============================] - 12s 30ms/step - loss: 1.7716\n",
      "Epoch 136/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 239.5716\n",
      "Epoch 137/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 28.4323\n",
      "Epoch 138/200\n",
      "393/393 [==============================] - 12s 31ms/step - loss: 15.4470\n",
      "Epoch 139/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 7.3407\n",
      "Epoch 140/200\n",
      "393/393 [==============================] - 12s 31ms/step - loss: 4.6879\n",
      "Epoch 141/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 2.9357\n",
      "Epoch 142/200\n",
      "393/393 [==============================] - 11s 27ms/step - loss: 1.9065\n",
      "Epoch 143/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 1.6594\n",
      "Epoch 144/200\n",
      "393/393 [==============================] - 12s 30ms/step - loss: 1.2323\n",
      "Epoch 145/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 1.2100\n",
      "Epoch 146/200\n",
      "393/393 [==============================] - 12s 30ms/step - loss: 0.7810\n",
      "Epoch 147/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 0.7111\n",
      "Epoch 148/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 0.5495\n",
      "Epoch 149/200\n",
      "393/393 [==============================] - 12s 30ms/step - loss: 0.6517\n",
      "Epoch 150/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 0.5456\n",
      "Epoch 151/200\n",
      "393/393 [==============================] - 12s 31ms/step - loss: 89.3146\n",
      "Epoch 152/200\n",
      "393/393 [==============================] - 11s 29ms/step - loss: 240.7340\n",
      "Epoch 153/200\n",
      "393/393 [==============================] - 11s 28ms/step - loss: 33.5504\n",
      "Epoch 154/200\n",
      "393/393 [==============================] - 11s 27ms/step - loss: 10.4729\n",
      "Epoch 155/200\n",
      "393/393 [==============================] - 12s 31ms/step - loss: 6.0290\n",
      "Epoch 156/200\n",
      "393/393 [==============================] - 10s 25ms/step - loss: 4.4730\n",
      "Epoch 157/200\n",
      "393/393 [==============================] - 13s 34ms/step - loss: 4.3001\n",
      "Epoch 158/200\n",
      "393/393 [==============================] - 12s 31ms/step - loss: 2.9218\n",
      "Epoch 159/200\n",
      "393/393 [==============================] - 12s 31ms/step - loss: 3.1426\n",
      "Epoch 160/200\n",
      "393/393 [==============================] - 12s 31ms/step - loss: 2.2210\n",
      "Epoch 161/200\n",
      "393/393 [==============================] - 12s 30ms/step - loss: 3.0892\n",
      "Epoch 162/200\n",
      "393/393 [==============================] - 14s 35ms/step - loss: 2.7210\n",
      "Epoch 163/200\n",
      "393/393 [==============================] - 17s 43ms/step - loss: 1.8940\n",
      "Epoch 164/200\n",
      "393/393 [==============================] - 18s 45ms/step - loss: 2.1873\n",
      "Epoch 165/200\n",
      "393/393 [==============================] - 18s 47ms/step - loss: 36.1586\n",
      "Epoch 166/200\n",
      "393/393 [==============================] - 18s 45ms/step - loss: 2.1338\n",
      "Epoch 167/200\n",
      "393/393 [==============================] - 18s 45ms/step - loss: 1.1061\n",
      "Epoch 168/200\n",
      "393/393 [==============================] - 17s 43ms/step - loss: 1.3974\n",
      "Epoch 169/200\n",
      "393/393 [==============================] - 17s 43ms/step - loss: 1.2523\n",
      "Epoch 170/200\n",
      "393/393 [==============================] - 18s 45ms/step - loss: 1.0963\n",
      "Epoch 171/200\n",
      "393/393 [==============================] - 18s 45ms/step - loss: 1.3914\n",
      "Epoch 172/200\n",
      "393/393 [==============================] - 16s 41ms/step - loss: 1.0328\n",
      "Epoch 173/200\n",
      "393/393 [==============================] - 17s 43ms/step - loss: 1.6930\n",
      "Epoch 174/200\n",
      "393/393 [==============================] - 17s 44ms/step - loss: 1.2666\n",
      "Epoch 175/200\n",
      "393/393 [==============================] - 15s 38ms/step - loss: 0.7302\n",
      "Epoch 176/200\n",
      "393/393 [==============================] - 13s 34ms/step - loss: 0.9898\n",
      "Epoch 177/200\n",
      "393/393 [==============================] - 13s 32ms/step - loss: 1.7079\n",
      "Epoch 178/200\n",
      "393/393 [==============================] - 15s 38ms/step - loss: 1.6552\n",
      "Epoch 179/200\n",
      "393/393 [==============================] - 14s 34ms/step - loss: 0.8956\n",
      "Epoch 180/200\n",
      "393/393 [==============================] - 13s 33ms/step - loss: 0.6293\n",
      "Epoch 181/200\n",
      "393/393 [==============================] - 13s 33ms/step - loss: 160.4176\n",
      "Epoch 182/200\n",
      "393/393 [==============================] - 13s 33ms/step - loss: 284.8364\n",
      "Epoch 183/200\n",
      "393/393 [==============================] - 12s 31ms/step - loss: 153.0123\n",
      "Epoch 184/200\n",
      "393/393 [==============================] - 13s 32ms/step - loss: 30.5965\n",
      "Epoch 185/200\n",
      "393/393 [==============================] - 12s 32ms/step - loss: 20.4277\n",
      "Epoch 186/200\n",
      "393/393 [==============================] - 13s 32ms/step - loss: 15.0077\n",
      "Epoch 187/200\n",
      "393/393 [==============================] - 13s 33ms/step - loss: 11.9669\n",
      "Epoch 188/200\n",
      "393/393 [==============================] - 12s 30ms/step - loss: 12.8149\n",
      "Epoch 189/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393/393 [==============================] - 13s 33ms/step - loss: 10.5743\n",
      "Epoch 190/200\n",
      "393/393 [==============================] - 12s 32ms/step - loss: 10.4247\n",
      "Epoch 191/200\n",
      "393/393 [==============================] - 12s 30ms/step - loss: 5.5666\n",
      "Epoch 192/200\n",
      "393/393 [==============================] - 13s 33ms/step - loss: 5.0395\n",
      "Epoch 193/200\n",
      "393/393 [==============================] - 13s 32ms/step - loss: 5.6385\n",
      "Epoch 194/200\n",
      "393/393 [==============================] - 13s 33ms/step - loss: 5.3013\n",
      "Epoch 195/200\n",
      "393/393 [==============================] - 12s 31ms/step - loss: 4.3048\n",
      "Epoch 196/200\n",
      "393/393 [==============================] - 12s 31ms/step - loss: 2.7427\n",
      "Epoch 197/200\n",
      "393/393 [==============================] - 14s 35ms/step - loss: 2.0441\n",
      "Epoch 198/200\n",
      "393/393 [==============================] - 16s 40ms/step - loss: 6.0813\n",
      "Epoch 199/200\n",
      "393/393 [==============================] - 14s 35ms/step - loss: 2.0151\n",
      "Epoch 200/200\n",
      "393/393 [==============================] - 12s 31ms/step - loss: 2.9250\n",
      "97/97 [==============================] - 1s 5ms/step\n",
      "R^squared: 0.9936606310935524\n",
      "MSE:  2.1326154746293287\n",
      "RMSE:  1.4603477238758338\n",
      "MAE: 0.9544235646828695\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Epoch 1/200\n",
      "393/393 [==============================] - 5s 7ms/step - loss: 7868.0508\n",
      "Epoch 2/200\n",
      "393/393 [==============================] - 3s 7ms/step - loss: 6279.0327\n",
      "Epoch 3/200\n",
      "393/393 [==============================] - 3s 7ms/step - loss: 5113.7183\n",
      "Epoch 4/200\n",
      "393/393 [==============================] - 3s 8ms/step - loss: 4141.3589\n",
      "Epoch 5/200\n",
      "393/393 [==============================] - 3s 9ms/step - loss: 3323.6243\n",
      "Epoch 6/200\n",
      "393/393 [==============================] - 4s 9ms/step - loss: 2638.2183\n",
      "Epoch 7/200\n",
      "393/393 [==============================] - 3s 7ms/step - loss: 2069.1448\n",
      "Epoch 8/200\n",
      "393/393 [==============================] - 3s 8ms/step - loss: 1604.2434\n",
      "Epoch 9/200\n",
      "393/393 [==============================] - 3s 7ms/step - loss: 1232.1196\n",
      "Epoch 10/200\n",
      "393/393 [==============================] - 3s 8ms/step - loss: 942.2481\n",
      "Epoch 11/200\n",
      "393/393 [==============================] - 3s 7ms/step - loss: 724.3375\n",
      "Epoch 12/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 567.8253\n",
      "Epoch 13/200\n",
      "393/393 [==============================] - 2s 6ms/step - loss: 461.9078\n",
      "Epoch 14/200\n",
      "393/393 [==============================] - 3s 8ms/step - loss: 395.2748\n",
      "Epoch 15/200\n",
      "393/393 [==============================] - 4s 9ms/step - loss: 357.2426\n",
      "Epoch 16/200\n",
      "393/393 [==============================] - 3s 7ms/step - loss: 337.8966\n",
      "Epoch 17/200\n",
      "393/393 [==============================] - 3s 7ms/step - loss: 329.5512\n",
      "Epoch 18/200\n",
      "393/393 [==============================] - 3s 7ms/step - loss: 326.4894\n",
      "Epoch 19/200\n",
      "393/393 [==============================] - 3s 7ms/step - loss: 325.6055\n",
      "Epoch 20/200\n",
      "393/393 [==============================] - 3s 8ms/step - loss: 325.4338\n",
      "Epoch 21/200\n",
      "393/393 [==============================] - 4s 10ms/step - loss: 325.4086\n",
      "Epoch 22/200\n",
      "393/393 [==============================] - 3s 9ms/step - loss: 325.3895\n",
      "Epoch 23/200\n",
      "393/393 [==============================] - 4s 11ms/step - loss: 325.4312\n",
      "Epoch 24/200\n",
      "393/393 [==============================] - 3s 8ms/step - loss: 325.4198\n",
      "Epoch 25/200\n",
      "393/393 [==============================] - 3s 7ms/step - loss: 325.4196\n",
      "Epoch 26/200\n",
      "393/393 [==============================] - 3s 7ms/step - loss: 325.4143\n",
      "Epoch 27/200\n",
      "393/393 [==============================] - 3s 8ms/step - loss: 325.4122\n",
      "Epoch 28/200\n",
      "393/393 [==============================] - 3s 8ms/step - loss: 325.4228\n",
      "Epoch 29/200\n",
      "393/393 [==============================] - 3s 7ms/step - loss: 325.4470\n",
      "Epoch 30/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 325.4121\n",
      "Epoch 31/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 325.4238\n",
      "Epoch 32/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 325.4311\n",
      "Epoch 33/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 324.8850\n",
      "Epoch 34/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 322.9592\n",
      "Epoch 35/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 320.3769\n",
      "Epoch 36/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 317.5512\n",
      "Epoch 37/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 313.6887\n",
      "Epoch 38/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 311.1602\n",
      "Epoch 39/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 309.4383\n",
      "Epoch 40/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 307.3871\n",
      "Epoch 41/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 305.7859\n",
      "Epoch 42/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 304.4914\n",
      "Epoch 43/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 302.8221\n",
      "Epoch 44/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 301.6151\n",
      "Epoch 45/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 301.0102\n",
      "Epoch 46/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 300.1515\n",
      "Epoch 47/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 299.7189\n",
      "Epoch 48/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 298.7850\n",
      "Epoch 49/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 299.0526\n",
      "Epoch 50/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 298.3103\n",
      "Epoch 51/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 296.9939\n",
      "Epoch 52/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 296.8412\n",
      "Epoch 53/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 295.6070\n",
      "Epoch 54/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 294.7418\n",
      "Epoch 55/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 294.4081\n",
      "Epoch 56/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 294.4895\n",
      "Epoch 57/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 291.9342\n",
      "Epoch 58/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 291.2881\n",
      "Epoch 59/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 289.4248\n",
      "Epoch 60/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 286.1720\n",
      "Epoch 61/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 285.0481\n",
      "Epoch 62/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 282.5089\n",
      "Epoch 63/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 279.8105\n",
      "Epoch 64/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 277.1757\n",
      "Epoch 65/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 276.6711\n",
      "Epoch 66/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 268.7484\n",
      "Epoch 67/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 265.8970\n",
      "Epoch 68/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 257.6057\n",
      "Epoch 69/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 255.1185\n",
      "Epoch 70/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 241.5594\n",
      "Epoch 71/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 231.8274\n",
      "Epoch 72/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 221.2801\n",
      "Epoch 73/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 213.6953\n",
      "Epoch 74/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 204.8925\n",
      "Epoch 75/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 202.7382\n",
      "Epoch 76/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 198.5447\n",
      "Epoch 77/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 194.5686\n",
      "Epoch 78/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 191.5916\n",
      "Epoch 79/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 187.6071\n",
      "Epoch 80/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 180.4919\n",
      "Epoch 81/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 158.4543\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393/393 [==============================] - 1s 2ms/step - loss: 129.5568\n",
      "Epoch 83/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 99.0158\n",
      "Epoch 84/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 72.7639\n",
      "Epoch 85/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 62.0991\n",
      "Epoch 86/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 54.9092\n",
      "Epoch 87/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 47.9215\n",
      "Epoch 88/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 44.2345\n",
      "Epoch 89/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 41.0995\n",
      "Epoch 90/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 38.2985\n",
      "Epoch 91/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 37.0569\n",
      "Epoch 92/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 38.0445\n",
      "Epoch 93/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 32.9975\n",
      "Epoch 94/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 29.1281\n",
      "Epoch 95/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 27.9657\n",
      "Epoch 96/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 24.6346\n",
      "Epoch 97/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 22.2639\n",
      "Epoch 98/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 20.9224\n",
      "Epoch 99/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 19.3804\n",
      "Epoch 100/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 18.4796\n",
      "Epoch 101/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 15.8927\n",
      "Epoch 102/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 17.2986\n",
      "Epoch 103/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 14.8207\n",
      "Epoch 104/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 14.8766\n",
      "Epoch 105/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 14.0428\n",
      "Epoch 106/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 13.6797\n",
      "Epoch 107/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 12.4366\n",
      "Epoch 108/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 12.6015\n",
      "Epoch 109/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 13.0578\n",
      "Epoch 110/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 11.1795\n",
      "Epoch 111/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 11.3426\n",
      "Epoch 112/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 11.6999\n",
      "Epoch 113/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 10.0530\n",
      "Epoch 114/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 9.5643\n",
      "Epoch 115/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 9.1397\n",
      "Epoch 116/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 8.7879\n",
      "Epoch 117/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 10.5396\n",
      "Epoch 118/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 7.8684\n",
      "Epoch 119/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 7.7583\n",
      "Epoch 120/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 7.2893\n",
      "Epoch 121/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 7.4138\n",
      "Epoch 122/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 7.3017\n",
      "Epoch 123/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 6.4947\n",
      "Epoch 124/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 6.6507\n",
      "Epoch 125/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 6.1699\n",
      "Epoch 126/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 5.1281\n",
      "Epoch 127/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 5.7871\n",
      "Epoch 128/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 4.5991\n",
      "Epoch 129/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 6.1121\n",
      "Epoch 130/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 5.2302\n",
      "Epoch 131/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 4.5666\n",
      "Epoch 132/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 4.4680\n",
      "Epoch 133/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 5.1701\n",
      "Epoch 134/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 4.0072\n",
      "Epoch 135/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 4.3409\n",
      "Epoch 136/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 4.8271\n",
      "Epoch 137/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 3.2325\n",
      "Epoch 138/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 3.9460\n",
      "Epoch 139/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 3.4935\n",
      "Epoch 140/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 3.9663\n",
      "Epoch 141/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 3.4745\n",
      "Epoch 142/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 3.4478\n",
      "Epoch 143/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 3.5274\n",
      "Epoch 144/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 3.5853\n",
      "Epoch 145/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 3.9273\n",
      "Epoch 146/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 3.0785\n",
      "Epoch 147/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 3.0213\n",
      "Epoch 148/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 2.4531\n",
      "Epoch 149/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 4.6709\n",
      "Epoch 150/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 2.7615\n",
      "Epoch 151/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 2.6802\n",
      "Epoch 152/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 2.1784\n",
      "Epoch 153/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 3.7531\n",
      "Epoch 154/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 2.2539\n",
      "Epoch 155/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 2.2765\n",
      "Epoch 156/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 1.9562\n",
      "Epoch 157/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 2.4116\n",
      "Epoch 158/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 2.2795\n",
      "Epoch 159/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 2.4088\n",
      "Epoch 160/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 2.3219\n",
      "Epoch 161/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 1.9947\n",
      "Epoch 162/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 1.9067\n",
      "Epoch 163/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 3.2906\n",
      "Epoch 164/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 2.9083\n",
      "Epoch 165/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 1.7349\n",
      "Epoch 166/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 2.2714\n",
      "Epoch 167/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 2.0329\n",
      "Epoch 168/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 1.4700\n",
      "Epoch 169/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 1.9213\n",
      "Epoch 170/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 1.9586\n",
      "Epoch 171/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 1.8088\n",
      "Epoch 172/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 1.4735\n",
      "Epoch 173/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 1.9950\n",
      "Epoch 174/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 1.9367\n",
      "Epoch 175/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 1.4640\n",
      "Epoch 176/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 1.8377\n",
      "Epoch 177/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 1.7341\n",
      "Epoch 178/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 1.8789\n",
      "Epoch 179/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393/393 [==============================] - 1s 2ms/step - loss: 1.8261\n",
      "Epoch 180/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 1.5166\n",
      "Epoch 181/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 1.6641\n",
      "Epoch 182/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 1.5150\n",
      "Epoch 183/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 1.7665\n",
      "Epoch 184/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 1.9246\n",
      "Epoch 185/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 1.5008\n",
      "Epoch 186/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 1.4945\n",
      "Epoch 187/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 1.4978\n",
      "Epoch 188/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 1.2988\n",
      "Epoch 189/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 1.5524\n",
      "Epoch 190/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 1.2997\n",
      "Epoch 191/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 1.2395\n",
      "Epoch 192/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 1.3852\n",
      "Epoch 193/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 1.2549\n",
      "Epoch 194/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 1.3719\n",
      "Epoch 195/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 1.1315\n",
      "Epoch 196/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 2.2476\n",
      "Epoch 197/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 1.3394\n",
      "Epoch 198/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 1.1308\n",
      "Epoch 199/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 1.5267\n",
      "Epoch 200/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 2.2932\n",
      "97/97 [==============================] - 0s 1ms/step\n",
      "R^squared: 0.9908775833994703\n",
      "MSE:  3.068855448453012\n",
      "RMSE:  1.7518149013103559\n",
      "MAE: 1.1006036779868968\n",
      "1/1 [==============================] - 0s 84ms/step\n"
     ]
    }
   ],
   "source": [
    "model_outputs_nn = {}\n",
    "sample_predicted_nn={}\n",
    "\n",
    "for i, (key, model) in enumerate(models.items()):\n",
    "    if key == 'MLP':\n",
    "        model, score, mse, rmse, mae=training_model(X_train_scaled, X_test_scaled, y_train, y_test ,model)\n",
    "        model_outputs_nn[key] = {'R-squared': score, 'MSE': mse, 'RMSE': rmse, 'MAE': mae}\n",
    "        sample_data = scaler.transform(sample2)\n",
    "        sample_predicted_nn[key]=model.predict(sample_data)\n",
    "    else:\n",
    "        model, score, mse, rmse, mae =nn_models(X_train_scaled, X_test_scaled, y_train, y_test, model, epoch_num=200, batch_size=16)\n",
    "        model_outputs_nn[key] = {'R-squared': score, 'MSE': mse, 'RMSE': rmse, 'MAE': mae}\n",
    "        sample_predicted_nn[key]=model.predict(sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "812503ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLP</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>RNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>0.999843</td>\n",
       "      <td>0.993661</td>\n",
       "      <td>0.990878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.052820</td>\n",
       "      <td>2.132615</td>\n",
       "      <td>3.068855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.229826</td>\n",
       "      <td>1.460348</td>\n",
       "      <td>1.751815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.161535</td>\n",
       "      <td>0.954424</td>\n",
       "      <td>1.100604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                MLP      LSTM       RNN\n",
       "R-squared  0.999843  0.993661  0.990878\n",
       "MSE        0.052820  2.132615  3.068855\n",
       "RMSE       0.229826  1.460348  1.751815\n",
       "MAE        0.161535  0.954424  1.100604"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_outputs_nn = pd.DataFrame(model_outputs_nn)\n",
    "model_outputs_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb32c520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MLP': array([ 65.08012646,  71.12291958,  99.96794486,  98.75865411,\n",
       "         99.40327189, 100.15074386, 101.12020297,  99.44519998,\n",
       "         95.60790053,  20.48921033,  51.79398514]),\n",
       " 'LSTM': array([[ 4.317101 ],\n",
       "        [ 3.5664444],\n",
       "        [ 5.873078 ],\n",
       "        [11.031271 ],\n",
       "        [ 6.0092354],\n",
       "        [ 5.258825 ],\n",
       "        [ 5.3275504],\n",
       "        [ 5.402327 ],\n",
       "        [ 5.6651707],\n",
       "        [ 5.888509 ],\n",
       "        [ 3.260572 ]], dtype=float32),\n",
       " 'RNN': array([[60.39218 ],\n",
       "        [60.392174],\n",
       "        [60.392174],\n",
       "        [60.392174],\n",
       "        [60.392174],\n",
       "        [60.392174],\n",
       "        [60.392174],\n",
       "        [60.392097],\n",
       "        [60.392174],\n",
       "        [60.392174],\n",
       "        [60.392174]], dtype=float32)}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_predicted_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c0cf342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_predicted_nn['LSTM'] = sample_predicted_nn['LSTM'].flatten()\n",
    "sample_predicted_nn['RNN'] = sample_predicted_nn['RNN'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ce245f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occ.</th>\n",
       "      <th>MLP</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>RNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.45</td>\n",
       "      <td>65.080126</td>\n",
       "      <td>4.317101</td>\n",
       "      <td>60.392181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.90</td>\n",
       "      <td>71.122920</td>\n",
       "      <td>3.566444</td>\n",
       "      <td>60.392174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.00</td>\n",
       "      <td>99.967945</td>\n",
       "      <td>5.873078</td>\n",
       "      <td>60.392174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.00</td>\n",
       "      <td>98.758654</td>\n",
       "      <td>11.031271</td>\n",
       "      <td>60.392174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.00</td>\n",
       "      <td>99.403272</td>\n",
       "      <td>6.009235</td>\n",
       "      <td>60.392174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>99.39</td>\n",
       "      <td>100.150744</td>\n",
       "      <td>5.258825</td>\n",
       "      <td>60.392174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>99.58</td>\n",
       "      <td>101.120203</td>\n",
       "      <td>5.327550</td>\n",
       "      <td>60.392174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>99.39</td>\n",
       "      <td>99.445200</td>\n",
       "      <td>5.402327</td>\n",
       "      <td>60.392097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>95.80</td>\n",
       "      <td>95.607901</td>\n",
       "      <td>5.665171</td>\n",
       "      <td>60.392174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23.40</td>\n",
       "      <td>20.489210</td>\n",
       "      <td>5.888509</td>\n",
       "      <td>60.392174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>53.05</td>\n",
       "      <td>51.793985</td>\n",
       "      <td>3.260572</td>\n",
       "      <td>60.392174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Occ.         MLP       LSTM        RNN\n",
       "0    65.45   65.080126   4.317101  60.392181\n",
       "1    70.90   71.122920   3.566444  60.392174\n",
       "2   100.00   99.967945   5.873078  60.392174\n",
       "3   100.00   98.758654  11.031271  60.392174\n",
       "4   100.00   99.403272   6.009235  60.392174\n",
       "5    99.39  100.150744   5.258825  60.392174\n",
       "6    99.58  101.120203   5.327550  60.392174\n",
       "7    99.39   99.445200   5.402327  60.392097\n",
       "8    95.80   95.607901   5.665171  60.392174\n",
       "9    23.40   20.489210   5.888509  60.392174\n",
       "10   53.05   51.793985   3.260572  60.392174"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_predicted_nn = pd.DataFrame(sample_predicted_nn)\n",
    "real_pred_nn=pd.concat([a[['Occ.']],sample_predicted_nn], axis=1)\n",
    "real_pred_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1af6328",
   "metadata": {},
   "source": [
    "## Dataset \n",
    "#x=zamansal girdiler ve Netto y=price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08dbeb3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flight Date</th>\n",
       "      <th>day_name</th>\n",
       "      <th>flight_month</th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>Days</th>\n",
       "      <th>dpt</th>\n",
       "      <th>dpt1</th>\n",
       "      <th>Netto</th>\n",
       "      <th>prıce</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>238.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>174.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>311.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>236.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>200.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Flight Date  day_name  flight_month  season  year  Days  dpt  dpt1  Netto  \\\n",
       "0            0         0             0       0  2020     4    0     0  177.0   \n",
       "1            1         0             0       0  2020     4    0     0  174.0   \n",
       "2            0         0             0       0  2020     4    1     0  253.0   \n",
       "3            2         1             0       0  2020     5    1     0  236.0   \n",
       "4            3         2             1       1  2020     7    0     0  251.0   \n",
       "\n",
       "    prıce  \n",
       "0  238.73  \n",
       "1  174.00  \n",
       "2  311.35  \n",
       "3  236.00  \n",
       "4  200.31  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1=dataset.loc[:,['Flight Date','day_name','flight_month','season','year','Days','dpt','dpt1','Netto','prıce']]\n",
    "dataset1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8e376b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset1.drop(['prıce'], axis=1) \n",
    "y = dataset1.iloc[:,-1:] \n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X,y.values.ravel(), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc670b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flight Date</th>\n",
       "      <th>day_name</th>\n",
       "      <th>flight_month</th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>Days</th>\n",
       "      <th>dpt</th>\n",
       "      <th>dpt1</th>\n",
       "      <th>Netto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>177.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>253.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>236.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>251.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9371</th>\n",
       "      <td>496</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>377.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9372</th>\n",
       "      <td>496</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>190</td>\n",
       "      <td>26</td>\n",
       "      <td>343.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9373</th>\n",
       "      <td>497</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>7</td>\n",
       "      <td>117</td>\n",
       "      <td>47</td>\n",
       "      <td>370.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9374</th>\n",
       "      <td>497</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>7</td>\n",
       "      <td>75</td>\n",
       "      <td>188</td>\n",
       "      <td>377.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9375</th>\n",
       "      <td>497</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>7</td>\n",
       "      <td>75</td>\n",
       "      <td>188</td>\n",
       "      <td>703.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9376 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Flight Date  day_name  flight_month  season  year  Days  dpt  dpt1  \\\n",
       "0               0         0             0       0  2020     4    0     0   \n",
       "1               1         0             0       0  2020     4    0     0   \n",
       "2               0         0             0       0  2020     4    1     0   \n",
       "3               2         1             0       0  2020     5    1     0   \n",
       "4               3         2             1       1  2020     7    0     0   \n",
       "...           ...       ...           ...     ...   ...   ...  ...   ...   \n",
       "9371          496         6             9       3  2022     6   24    12   \n",
       "9372          496         6             9       3  2022     6  190    26   \n",
       "9373          497         2             9       3  2022     7  117    47   \n",
       "9374          497         2             9       3  2022     7   75   188   \n",
       "9375          497         2             9       3  2022     7   75   188   \n",
       "\n",
       "       Netto  \n",
       "0     177.00  \n",
       "1     174.00  \n",
       "2     253.00  \n",
       "3     236.00  \n",
       "4     251.00  \n",
       "...      ...  \n",
       "9371  377.18  \n",
       "9372  343.18  \n",
       "9373  370.00  \n",
       "9374  377.18  \n",
       "9375  703.18  \n",
       "\n",
       "[9376 rows x 9 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9b9e831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Flight Date', 'day_name', 'flight_month', 'season', 'year', 'Days',\n",
       "       'dpt', 'dpt1', 'Netto'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e204930c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prıce</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>238.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>174.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>311.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>236.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9371</th>\n",
       "      <td>798.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9372</th>\n",
       "      <td>741.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9373</th>\n",
       "      <td>882.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9374</th>\n",
       "      <td>844.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9375</th>\n",
       "      <td>1064.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9376 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        prıce\n",
       "0      238.73\n",
       "1      174.00\n",
       "2      311.35\n",
       "3      236.00\n",
       "4      200.31\n",
       "...       ...\n",
       "9371   798.13\n",
       "9372   741.62\n",
       "9373   882.82\n",
       "9374   844.69\n",
       "9375  1064.55\n",
       "\n",
       "[9376 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2ba0862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flight Date</th>\n",
       "      <th>day_name</th>\n",
       "      <th>flight_month</th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>Days</th>\n",
       "      <th>dpt</th>\n",
       "      <th>dpt1</th>\n",
       "      <th>Netto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>325</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>149.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>481</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "      <td>156</td>\n",
       "      <td>170</td>\n",
       "      <td>246.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>703</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2022</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>69</td>\n",
       "      <td>475.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>552</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>123</td>\n",
       "      <td>23</td>\n",
       "      <td>660.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>210</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>356.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>561</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>64</td>\n",
       "      <td>162.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>560</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>7</td>\n",
       "      <td>88</td>\n",
       "      <td>71</td>\n",
       "      <td>150.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>490</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>7</td>\n",
       "      <td>69</td>\n",
       "      <td>156</td>\n",
       "      <td>162.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>507</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>190</td>\n",
       "      <td>188</td>\n",
       "      <td>200.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>532</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "      <td>165</td>\n",
       "      <td>259.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>405</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>32</td>\n",
       "      <td>197.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Flight Date  day_name  flight_month  season  year  Days  dpt  dpt1   Netto\n",
       "0           325         5             6       2  2021     3   26    28  149.00\n",
       "1           481         4             8       3  2022     2  156   170  246.00\n",
       "2           703         2            12       4  2022     7   24    69  475.82\n",
       "3           552         6             6       2  2022     6  123    23  660.36\n",
       "4           210         1             5       2  2021     5   24    26  356.36\n",
       "5           561         3             4       3  2022     1   35    64  162.00\n",
       "6           560         2             5       2  2022     7   88    71  150.00\n",
       "7           490         2             5       2  2022     7   69   156  162.00\n",
       "8           507         5             9       3  2022     3  190   188  200.00\n",
       "9           532         2             9       3  2022     7   45   165  259.00\n",
       "10          405         3             4       3  2021     1   42    32  197.00"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample3 = a.loc[:,['Flight Date', 'day_name', 'flight_month', 'season', 'year', 'Days',\n",
    "       'dpt', 'dpt1', 'Netto']]\n",
    "sample3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c82a288",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = RandomForestRegressor(n_estimators = 7, max_depth = 30,min_samples_split=5,random_state = 42)\n",
    "DT_Regressor = tree.DecisionTreeRegressor()\n",
    "ridge = Ridge(alpha=1.0)\n",
    "lasso_cv = LassoCV(alphas = None, cv = 10, max_iter = 100000, normalize = True)\n",
    "lr = LinearRegression()\n",
    "models = { 'Random forest': rf2,'Decision tree': DT_Regressor,'Ridge regression': ridge,\n",
    "          'Lasso regression': lasso_cv,'Linear regression': lr,'XGBOOST': xgb_reg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "284d13b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^squared: 0.8900708234010583\n",
      "MSE:  10038.708768320093\n",
      "RMSE:  100.19335690713278\n",
      "MAE: 60.75765245361859\n",
      "R^squared: 0.8205371711244561\n",
      "MSE:  16388.506942003194\n",
      "RMSE:  128.01760403164556\n",
      "MAE: 77.0298061389337\n",
      "R^squared: 0.7057997796519864\n",
      "MSE:  26866.300858636107\n",
      "RMSE:  163.90942882774044\n",
      "MAE: 123.14051230589598\n",
      "R^squared: 0.7057926958653206\n",
      "MSE:  26866.947748511164\n",
      "RMSE:  163.91140213088033\n",
      "MAE: 123.1500624538953\n",
      "R^squared: 0.7058026469516419\n",
      "MSE:  26866.039017448144\n",
      "RMSE:  163.9086300883762\n",
      "MAE: 123.14230334234634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\90541\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^squared: 0.8867571815018817\n",
      "MSE:  10341.309834001664\n",
      "RMSE:  101.69223094219963\n",
      "MAE: 58.13741372835341\n"
     ]
    }
   ],
   "source": [
    "model_outputs2 = {}\n",
    "sample_predicted2={}\n",
    "\n",
    "for i, (key, model) in enumerate(models.items()):\n",
    "    model, score, mse, rmse, mae = training_model(X_train2, X_test2, y_train2, y_test2 , model=model)\n",
    "    model_outputs2[key] = {'R-squared': score, 'MSE': mse, 'RMSE': rmse, 'MAE': mae}\n",
    "    sample_predicted2[key]=model.predict(sample3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "691c66de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random forest</th>\n",
       "      <th>Decision tree</th>\n",
       "      <th>Ridge regression</th>\n",
       "      <th>Lasso regression</th>\n",
       "      <th>Linear regression</th>\n",
       "      <th>XGBOOST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>0.890071</td>\n",
       "      <td>0.820537</td>\n",
       "      <td>0.705800</td>\n",
       "      <td>0.705793</td>\n",
       "      <td>0.705803</td>\n",
       "      <td>0.886757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>10038.708768</td>\n",
       "      <td>16388.506942</td>\n",
       "      <td>26866.300859</td>\n",
       "      <td>26866.947749</td>\n",
       "      <td>26866.039017</td>\n",
       "      <td>10341.309834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>100.193357</td>\n",
       "      <td>128.017604</td>\n",
       "      <td>163.909429</td>\n",
       "      <td>163.911402</td>\n",
       "      <td>163.908630</td>\n",
       "      <td>101.692231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>60.757652</td>\n",
       "      <td>77.029806</td>\n",
       "      <td>123.140512</td>\n",
       "      <td>123.150062</td>\n",
       "      <td>123.142303</td>\n",
       "      <td>58.137414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Random forest  Decision tree  Ridge regression  Lasso regression  \\\n",
       "R-squared       0.890071       0.820537          0.705800          0.705793   \n",
       "MSE         10038.708768   16388.506942      26866.300859      26866.947749   \n",
       "RMSE          100.193357     128.017604        163.909429        163.911402   \n",
       "MAE            60.757652      77.029806        123.140512        123.150062   \n",
       "\n",
       "           Linear regression       XGBOOST  \n",
       "R-squared           0.705803      0.886757  \n",
       "MSE             26866.039017  10341.309834  \n",
       "RMSE              163.908630    101.692231  \n",
       "MAE               123.142303     58.137414  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_outputs2 = pd.DataFrame(model_outputs2)\n",
    "model_outputs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8165feaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_predicted2 = pd.DataFrame(sample_predicted2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f016d947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prıce</th>\n",
       "      <th>Random forest</th>\n",
       "      <th>Decision tree</th>\n",
       "      <th>Ridge regression</th>\n",
       "      <th>Lasso regression</th>\n",
       "      <th>Linear regression</th>\n",
       "      <th>XGBOOST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116.47</td>\n",
       "      <td>152.975929</td>\n",
       "      <td>140.26</td>\n",
       "      <td>221.597274</td>\n",
       "      <td>222.303850</td>\n",
       "      <td>221.639390</td>\n",
       "      <td>211.741592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>203.02</td>\n",
       "      <td>511.263476</td>\n",
       "      <td>688.55</td>\n",
       "      <td>543.138838</td>\n",
       "      <td>542.852175</td>\n",
       "      <td>543.372799</td>\n",
       "      <td>491.367340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1038.15</td>\n",
       "      <td>680.992714</td>\n",
       "      <td>920.26</td>\n",
       "      <td>722.886516</td>\n",
       "      <td>726.904661</td>\n",
       "      <td>722.149970</td>\n",
       "      <td>702.169739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1307.82</td>\n",
       "      <td>1248.962869</td>\n",
       "      <td>1115.19</td>\n",
       "      <td>1085.623522</td>\n",
       "      <td>1083.774199</td>\n",
       "      <td>1085.693297</td>\n",
       "      <td>1147.304077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>674.56</td>\n",
       "      <td>390.040952</td>\n",
       "      <td>390.25</td>\n",
       "      <td>602.918853</td>\n",
       "      <td>600.081850</td>\n",
       "      <td>603.272653</td>\n",
       "      <td>379.074982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>243.50</td>\n",
       "      <td>706.916548</td>\n",
       "      <td>739.19</td>\n",
       "      <td>447.894319</td>\n",
       "      <td>448.221469</td>\n",
       "      <td>448.129691</td>\n",
       "      <td>704.586731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>303.87</td>\n",
       "      <td>685.033810</td>\n",
       "      <td>701.41</td>\n",
       "      <td>405.121645</td>\n",
       "      <td>404.188273</td>\n",
       "      <td>405.450326</td>\n",
       "      <td>687.676025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>184.08</td>\n",
       "      <td>696.158000</td>\n",
       "      <td>689.08</td>\n",
       "      <td>451.363241</td>\n",
       "      <td>449.746205</td>\n",
       "      <td>451.874700</td>\n",
       "      <td>633.375061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>275.78</td>\n",
       "      <td>614.844871</td>\n",
       "      <td>613.48</td>\n",
       "      <td>449.268383</td>\n",
       "      <td>449.793270</td>\n",
       "      <td>449.379824</td>\n",
       "      <td>540.868103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>327.88</td>\n",
       "      <td>484.611960</td>\n",
       "      <td>369.36</td>\n",
       "      <td>530.596938</td>\n",
       "      <td>531.188766</td>\n",
       "      <td>530.685765</td>\n",
       "      <td>521.367310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>122.03</td>\n",
       "      <td>177.951929</td>\n",
       "      <td>170.45</td>\n",
       "      <td>296.625646</td>\n",
       "      <td>298.770619</td>\n",
       "      <td>296.271767</td>\n",
       "      <td>158.151566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prıce  Random forest  Decision tree  Ridge regression  Lasso regression  \\\n",
       "0    116.47     152.975929         140.26        221.597274        222.303850   \n",
       "1    203.02     511.263476         688.55        543.138838        542.852175   \n",
       "2   1038.15     680.992714         920.26        722.886516        726.904661   \n",
       "3   1307.82    1248.962869        1115.19       1085.623522       1083.774199   \n",
       "4    674.56     390.040952         390.25        602.918853        600.081850   \n",
       "5    243.50     706.916548         739.19        447.894319        448.221469   \n",
       "6    303.87     685.033810         701.41        405.121645        404.188273   \n",
       "7    184.08     696.158000         689.08        451.363241        449.746205   \n",
       "8    275.78     614.844871         613.48        449.268383        449.793270   \n",
       "9    327.88     484.611960         369.36        530.596938        531.188766   \n",
       "10   122.03     177.951929         170.45        296.625646        298.770619   \n",
       "\n",
       "    Linear regression      XGBOOST  \n",
       "0          221.639390   211.741592  \n",
       "1          543.372799   491.367340  \n",
       "2          722.149970   702.169739  \n",
       "3         1085.693297  1147.304077  \n",
       "4          603.272653   379.074982  \n",
       "5          448.129691   704.586731  \n",
       "6          405.450326   687.676025  \n",
       "7          451.874700   633.375061  \n",
       "8          449.379824   540.868103  \n",
       "9          530.685765   521.367310  \n",
       "10         296.271767   158.151566  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_pred=pd.concat([a[['prıce']],sample_predicted2], axis=1)\n",
    "real_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "61abd402",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled2 = scaler.fit_transform(X_train2)\n",
    "X_test_scaled2 = scaler.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "90ffe26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_items2 = np.reshape(X_train_scaled2, (X_train_scaled2.shape[0], X_train_scaled2.shape[1], 1))\n",
    "X_test_items2 = np.reshape(X_test_scaled2, (X_test_scaled2.shape[0], X_test_scaled2.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "548bbc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = { 'MLP': mlp,'LSTM': modellstm,'RNN': rnn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8fea5ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^squared: 0.808207733542835\n",
      "MSE:  17514.428530687834\n",
      "RMSE:  132.34208903704004\n",
      "MAE: 92.33475673381965\n",
      "Epoch 1/200\n",
      "393/393 [==============================] - 3s 4ms/step - loss: 287117.8438\n",
      "Epoch 2/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 254169.4375\n",
      "Epoch 3/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 236395.4219\n",
      "Epoch 4/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 221908.3125\n",
      "Epoch 5/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 209281.0781\n",
      "Epoch 6/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 197941.2500\n",
      "Epoch 7/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 187565.7500\n",
      "Epoch 8/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 178003.0781\n",
      "Epoch 9/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 169128.5000\n",
      "Epoch 10/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 160896.7188\n",
      "Epoch 11/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 153244.7812\n",
      "Epoch 12/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 146145.1719\n",
      "Epoch 13/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 139581.5469\n",
      "Epoch 14/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 133535.6094\n",
      "Epoch 15/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 128003.3594\n",
      "Epoch 16/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 116647.0625\n",
      "Epoch 17/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 106235.7031\n",
      "Epoch 18/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 99824.9219\n",
      "Epoch 19/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 93448.3281\n",
      "Epoch 20/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 87715.4688\n",
      "Epoch 21/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 82564.1250\n",
      "Epoch 22/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 77550.6406\n",
      "Epoch 23/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 72873.2500\n",
      "Epoch 24/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 69291.1641\n",
      "Epoch 25/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 64744.4102\n",
      "Epoch 26/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 60861.4023\n",
      "Epoch 27/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 57406.1523\n",
      "Epoch 28/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 54452.7969\n",
      "Epoch 29/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 51696.5547\n",
      "Epoch 30/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 49116.7695\n",
      "Epoch 31/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 47068.2031\n",
      "Epoch 32/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 45329.8203\n",
      "Epoch 33/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 43681.1562\n",
      "Epoch 34/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 41018.0742\n",
      "Epoch 35/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 39971.9141\n",
      "Epoch 36/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 37917.6055\n",
      "Epoch 37/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 36787.2227\n",
      "Epoch 38/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 35853.9688\n",
      "Epoch 39/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 34493.9141\n",
      "Epoch 40/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 33652.5664\n",
      "Epoch 41/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 32890.1758\n",
      "Epoch 42/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 31944.1602\n",
      "Epoch 43/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 31155.8086\n",
      "Epoch 44/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 30418.8398\n",
      "Epoch 45/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 30124.9551\n",
      "Epoch 46/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 29484.1309\n",
      "Epoch 47/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 28919.9121\n",
      "Epoch 48/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 28432.1621\n",
      "Epoch 49/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 28475.4375\n",
      "Epoch 50/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 27843.6328\n",
      "Epoch 51/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 27319.5742\n",
      "Epoch 52/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 27001.2109\n",
      "Epoch 53/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 26672.3066\n",
      "Epoch 54/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 26171.4941\n",
      "Epoch 55/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 25988.3066\n",
      "Epoch 56/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 25700.8027\n",
      "Epoch 57/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 25380.3047\n",
      "Epoch 58/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 25395.2324\n",
      "Epoch 59/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 24748.6230\n",
      "Epoch 60/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 24377.4805\n",
      "Epoch 61/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 24292.1426\n",
      "Epoch 62/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 23802.9824\n",
      "Epoch 63/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 23782.4863\n",
      "Epoch 64/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 23378.1367\n",
      "Epoch 65/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 23111.4375\n",
      "Epoch 66/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 22962.1582\n",
      "Epoch 67/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 22715.0000\n",
      "Epoch 68/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 22416.1855\n",
      "Epoch 69/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 22197.5156\n",
      "Epoch 70/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 22069.9922\n",
      "Epoch 71/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 21786.6191\n",
      "Epoch 72/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 21721.6543\n",
      "Epoch 73/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 21412.8613\n",
      "Epoch 74/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 21371.6738\n",
      "Epoch 75/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 21029.2227\n",
      "Epoch 76/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 20813.0703\n",
      "Epoch 77/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 20770.1699\n",
      "Epoch 78/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 20404.0586\n",
      "Epoch 79/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 20313.0742\n",
      "Epoch 80/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 19984.7500\n",
      "Epoch 81/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 19897.9062\n",
      "Epoch 82/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 19605.5840\n",
      "Epoch 83/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 19594.2715\n",
      "Epoch 84/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 19341.0957\n",
      "Epoch 85/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 19074.6875\n",
      "Epoch 86/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 19121.1543\n",
      "Epoch 87/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 18875.0293\n",
      "Epoch 88/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 18687.4043\n",
      "Epoch 89/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 18518.2812\n",
      "Epoch 90/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 18563.3965\n",
      "Epoch 91/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 18516.6582\n",
      "Epoch 92/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 18310.8887\n",
      "Epoch 93/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393/393 [==============================] - 2s 4ms/step - loss: 18145.6934\n",
      "Epoch 94/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 17946.3789\n",
      "Epoch 95/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 17991.8984\n",
      "Epoch 96/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 17918.2910\n",
      "Epoch 97/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 17525.0176\n",
      "Epoch 98/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 17526.8809\n",
      "Epoch 99/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 17473.9492\n",
      "Epoch 100/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 17296.5918\n",
      "Epoch 101/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 17290.5840\n",
      "Epoch 102/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 17183.8965\n",
      "Epoch 103/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 16943.2559\n",
      "Epoch 104/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 17069.2988\n",
      "Epoch 105/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 16970.7871\n",
      "Epoch 106/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 16794.0273\n",
      "Epoch 107/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 16858.8184\n",
      "Epoch 108/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 16712.6680\n",
      "Epoch 109/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 16556.2656\n",
      "Epoch 110/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 16505.0098\n",
      "Epoch 111/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 16506.0879\n",
      "Epoch 112/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 16486.9336\n",
      "Epoch 113/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 16481.7031\n",
      "Epoch 114/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 16176.5742\n",
      "Epoch 115/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 16147.9561\n",
      "Epoch 116/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 16148.8398\n",
      "Epoch 117/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 16038.2578\n",
      "Epoch 118/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 16181.6523\n",
      "Epoch 119/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 16094.5225\n",
      "Epoch 120/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 16149.9736\n",
      "Epoch 121/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 16130.9268\n",
      "Epoch 122/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 16105.8496\n",
      "Epoch 123/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 15765.7734\n",
      "Epoch 124/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 15985.1611\n",
      "Epoch 125/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 15968.4521\n",
      "Epoch 126/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 15673.6377\n",
      "Epoch 127/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 15651.8672\n",
      "Epoch 128/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 15614.1455\n",
      "Epoch 129/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 15714.0674\n",
      "Epoch 130/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 15534.6016\n",
      "Epoch 131/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 15614.6865\n",
      "Epoch 132/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 15602.4326\n",
      "Epoch 133/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 15662.5508\n",
      "Epoch 134/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 15665.7002\n",
      "Epoch 135/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 15289.9883\n",
      "Epoch 136/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 15364.3447\n",
      "Epoch 137/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 15384.4697\n",
      "Epoch 138/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 15281.5811\n",
      "Epoch 139/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 15344.0830\n",
      "Epoch 140/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 15159.4639\n",
      "Epoch 141/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 15222.9463\n",
      "Epoch 142/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 15264.7520\n",
      "Epoch 143/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 15128.5361\n",
      "Epoch 144/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 15062.2725\n",
      "Epoch 145/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 15115.9395\n",
      "Epoch 146/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 14879.2715\n",
      "Epoch 147/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 15030.7734\n",
      "Epoch 148/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 14949.6309\n",
      "Epoch 149/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 14815.9150\n",
      "Epoch 150/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 14900.4873\n",
      "Epoch 151/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 14942.2002\n",
      "Epoch 152/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 14672.8252\n",
      "Epoch 153/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 14749.1582\n",
      "Epoch 154/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 14849.6816\n",
      "Epoch 155/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 14882.6465\n",
      "Epoch 156/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 14589.3711\n",
      "Epoch 157/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 14824.2061\n",
      "Epoch 158/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 14698.1719\n",
      "Epoch 159/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 14646.4561\n",
      "Epoch 160/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 14452.5459\n",
      "Epoch 161/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 14481.6084\n",
      "Epoch 162/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 14577.4824\n",
      "Epoch 163/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 14529.8320\n",
      "Epoch 164/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 14405.2441\n",
      "Epoch 165/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 14477.8438\n",
      "Epoch 166/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 14454.2793\n",
      "Epoch 167/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 14456.1807\n",
      "Epoch 168/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 14421.7480\n",
      "Epoch 169/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 14413.9902\n",
      "Epoch 170/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 14307.8223\n",
      "Epoch 171/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 14448.3867\n",
      "Epoch 172/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 14556.6562\n",
      "Epoch 173/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 14158.5508\n",
      "Epoch 174/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 14432.4268\n",
      "Epoch 175/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 14289.6758\n",
      "Epoch 176/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 14094.3428\n",
      "Epoch 177/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 14447.3916\n",
      "Epoch 178/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 14137.3486\n",
      "Epoch 179/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 14095.5029\n",
      "Epoch 180/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 14124.7432\n",
      "Epoch 181/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 14423.3418\n",
      "Epoch 182/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 14111.3184\n",
      "Epoch 183/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 14166.8896\n",
      "Epoch 184/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 14078.0400\n",
      "Epoch 185/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 13983.0596\n",
      "Epoch 186/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393/393 [==============================] - 2s 4ms/step - loss: 13917.0020\n",
      "Epoch 187/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 13943.3730\n",
      "Epoch 188/200\n",
      "393/393 [==============================] - 1s 4ms/step - loss: 13981.3164\n",
      "Epoch 189/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 13929.8174\n",
      "Epoch 190/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 13763.7793\n",
      "Epoch 191/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 13746.9463\n",
      "Epoch 192/200\n",
      "393/393 [==============================] - 2s 6ms/step - loss: 13898.1406\n",
      "Epoch 193/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 13717.2334\n",
      "Epoch 194/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 13789.2910\n",
      "Epoch 195/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 14401.9375\n",
      "Epoch 196/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 13678.2305\n",
      "Epoch 197/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 13964.8770\n",
      "Epoch 198/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 13741.0430\n",
      "Epoch 199/200\n",
      "393/393 [==============================] - 2s 5ms/step - loss: 13984.2588\n",
      "Epoch 200/200\n",
      "393/393 [==============================] - 2s 4ms/step - loss: 13734.5947\n",
      "97/97 [==============================] - 0s 1ms/step\n",
      "R^squared: 0.8296071803438458\n",
      "MSE:  15560.23565046412\n",
      "RMSE:  124.74067360113187\n",
      "MAE: 86.81532706945661\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "Epoch 1/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 307325.2188\n",
      "Epoch 2/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 290612.3438\n",
      "Epoch 3/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 280850.0938\n",
      "Epoch 4/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 272580.8125\n",
      "Epoch 5/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 265097.0000\n",
      "Epoch 6/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 258120.1875\n",
      "Epoch 7/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 251492.5312\n",
      "Epoch 8/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 245135.4219\n",
      "Epoch 9/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 238996.8125\n",
      "Epoch 10/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 233030.3750\n",
      "Epoch 11/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 227237.6875\n",
      "Epoch 12/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 221624.0156\n",
      "Epoch 13/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 216083.6719\n",
      "Epoch 14/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 210756.7812\n",
      "Epoch 15/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 205355.6875\n",
      "Epoch 16/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 200211.7031\n",
      "Epoch 17/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 195120.7500\n",
      "Epoch 18/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 190216.3125\n",
      "Epoch 19/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 185365.7500\n",
      "Epoch 20/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 180860.7344\n",
      "Epoch 21/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 176758.4375\n",
      "Epoch 22/200\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 172489.4531\n",
      "Epoch 23/200\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 168203.1406\n",
      "Epoch 24/200\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 163361.2969\n",
      "Epoch 25/200\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 158869.0625\n",
      "Epoch 26/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 154533.8906\n",
      "Epoch 27/200\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 150390.0469\n",
      "Epoch 28/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 146408.1719\n",
      "Epoch 29/200\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 142428.5938\n",
      "Epoch 30/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 138625.0156\n",
      "Epoch 31/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 135019.3906\n",
      "Epoch 32/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 131342.5156\n",
      "Epoch 33/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 127712.9844\n",
      "Epoch 34/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 123888.6328\n",
      "Epoch 35/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 120075.5234\n",
      "Epoch 36/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 116634.8047\n",
      "Epoch 37/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 113449.5000\n",
      "Epoch 38/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 110091.8516\n",
      "Epoch 39/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 107079.7031\n",
      "Epoch 40/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 103766.9375\n",
      "Epoch 41/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 100954.1562\n",
      "Epoch 42/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 98274.6562\n",
      "Epoch 43/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 94898.0469\n",
      "Epoch 44/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 92088.3594\n",
      "Epoch 45/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 89325.1406\n",
      "Epoch 46/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 86726.2656\n",
      "Epoch 47/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 84266.8438\n",
      "Epoch 48/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 81874.6172\n",
      "Epoch 49/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 79696.0078\n",
      "Epoch 50/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 77268.7891\n",
      "Epoch 51/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 75074.3281\n",
      "Epoch 52/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 72956.5391\n",
      "Epoch 53/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 70770.7109\n",
      "Epoch 54/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 68791.2812\n",
      "Epoch 55/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 66798.8125\n",
      "Epoch 56/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 64887.3594\n",
      "Epoch 57/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 63006.1289\n",
      "Epoch 58/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 61477.4961\n",
      "Epoch 59/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 59619.8047\n",
      "Epoch 60/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 58032.9766\n",
      "Epoch 61/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 56600.3516\n",
      "Epoch 62/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 55293.4727\n",
      "Epoch 63/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 53630.8906\n",
      "Epoch 64/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 52340.3633\n",
      "Epoch 65/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 51029.3203\n",
      "Epoch 66/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 49846.6250\n",
      "Epoch 67/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 48592.6836\n",
      "Epoch 68/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 47442.7930\n",
      "Epoch 69/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 46539.2031\n",
      "Epoch 70/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 45093.5117\n",
      "Epoch 71/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 44108.3203\n",
      "Epoch 72/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 43194.2734\n",
      "Epoch 73/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 42296.8633\n",
      "Epoch 74/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 41382.1680\n",
      "Epoch 75/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 40596.2734\n",
      "Epoch 76/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 39921.3867\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393/393 [==============================] - 1s 2ms/step - loss: 39317.0195\n",
      "Epoch 78/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 38554.7617\n",
      "Epoch 79/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 37970.2891\n",
      "Epoch 80/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 37415.6562\n",
      "Epoch 81/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 37091.5117\n",
      "Epoch 82/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 36645.3281\n",
      "Epoch 83/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 36299.0898\n",
      "Epoch 84/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 35887.2734\n",
      "Epoch 85/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 35599.4102\n",
      "Epoch 86/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 35288.7422\n",
      "Epoch 87/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 34956.7148\n",
      "Epoch 88/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 34711.6758\n",
      "Epoch 89/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 34512.6484\n",
      "Epoch 90/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 34165.7812\n",
      "Epoch 91/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 34073.5469\n",
      "Epoch 92/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 33881.3672\n",
      "Epoch 93/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 33744.7031\n",
      "Epoch 94/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 33384.5547\n",
      "Epoch 95/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 33195.2969\n",
      "Epoch 96/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 33021.2578\n",
      "Epoch 97/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 32946.6641\n",
      "Epoch 98/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 32624.0430\n",
      "Epoch 99/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 32484.9375\n",
      "Epoch 100/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 32305.9453\n",
      "Epoch 101/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 32033.2793\n",
      "Epoch 102/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 31650.0117\n",
      "Epoch 103/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 31551.3652\n",
      "Epoch 104/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 31417.2676\n",
      "Epoch 105/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 31476.0527\n",
      "Epoch 106/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 31101.3203\n",
      "Epoch 107/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 30635.8281\n",
      "Epoch 108/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 30439.6602\n",
      "Epoch 109/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 30107.4297\n",
      "Epoch 110/200\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 29969.8516\n",
      "Epoch 111/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 29778.3516\n",
      "Epoch 112/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 29950.6836\n",
      "Epoch 113/200\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 29729.7363\n",
      "Epoch 114/200\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 29426.6953\n",
      "Epoch 115/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 29226.4316\n",
      "Epoch 116/200\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 29056.1016\n",
      "Epoch 117/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 28985.6055\n",
      "Epoch 118/200\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 28788.7383\n",
      "Epoch 119/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 28716.0059\n",
      "Epoch 120/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 28516.6914\n",
      "Epoch 121/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 28582.3242\n",
      "Epoch 122/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 28124.0957\n",
      "Epoch 123/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 28049.5215\n",
      "Epoch 124/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 28050.7715\n",
      "Epoch 125/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 27993.4414\n",
      "Epoch 126/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 27862.7793\n",
      "Epoch 127/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 27552.5469\n",
      "Epoch 128/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 27577.4297\n",
      "Epoch 129/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 27445.4414\n",
      "Epoch 130/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 27339.8301\n",
      "Epoch 131/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 27252.6074\n",
      "Epoch 132/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 26923.1973\n",
      "Epoch 133/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 26999.7715\n",
      "Epoch 134/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 26810.0449\n",
      "Epoch 135/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 26574.7871\n",
      "Epoch 136/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 26571.6152\n",
      "Epoch 137/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 26379.5566\n",
      "Epoch 138/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 26236.8594\n",
      "Epoch 139/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 25941.9609\n",
      "Epoch 140/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 25926.4668\n",
      "Epoch 141/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 25738.7031\n",
      "Epoch 142/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 25643.1074\n",
      "Epoch 143/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 25357.3359\n",
      "Epoch 144/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 25168.6172\n",
      "Epoch 145/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 25104.9434\n",
      "Epoch 146/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 25277.4961\n",
      "Epoch 147/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 24882.2500\n",
      "Epoch 148/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 24622.5254\n",
      "Epoch 149/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 24502.1855\n",
      "Epoch 150/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 24414.2656\n",
      "Epoch 151/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 24214.8457\n",
      "Epoch 152/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 24154.7832\n",
      "Epoch 153/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 24297.4121\n",
      "Epoch 154/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 23937.2559\n",
      "Epoch 155/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 23765.4570\n",
      "Epoch 156/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 23664.2090\n",
      "Epoch 157/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 23550.5605\n",
      "Epoch 158/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 23627.7480\n",
      "Epoch 159/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 23299.6562\n",
      "Epoch 160/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 23266.3125\n",
      "Epoch 161/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 23075.0059\n",
      "Epoch 162/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 23079.5762\n",
      "Epoch 163/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 23039.1289\n",
      "Epoch 164/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 22857.0117\n",
      "Epoch 165/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 22815.1211\n",
      "Epoch 166/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 22712.5898\n",
      "Epoch 167/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 22775.7598\n",
      "Epoch 168/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 22552.5996\n",
      "Epoch 169/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 22484.0449\n",
      "Epoch 170/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393/393 [==============================] - 1s 2ms/step - loss: 22273.0527\n",
      "Epoch 171/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 22221.0215\n",
      "Epoch 172/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 22147.6523\n",
      "Epoch 173/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 21953.5586\n",
      "Epoch 174/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 22001.6816\n",
      "Epoch 175/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 21885.7715\n",
      "Epoch 176/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 21778.5039\n",
      "Epoch 177/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 21732.7949\n",
      "Epoch 178/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 21598.1895\n",
      "Epoch 179/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 21481.7051\n",
      "Epoch 180/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 21403.8984\n",
      "Epoch 181/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 21338.8633\n",
      "Epoch 182/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 21275.2363\n",
      "Epoch 183/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 21427.7949\n",
      "Epoch 184/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 21205.9297\n",
      "Epoch 185/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 20999.2441\n",
      "Epoch 186/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 20939.9062\n",
      "Epoch 187/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 20908.1641\n",
      "Epoch 188/200\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 20907.3574\n",
      "Epoch 189/200\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 20723.8125\n",
      "Epoch 190/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 20682.5273\n",
      "Epoch 191/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 20626.1836\n",
      "Epoch 192/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 20470.1445\n",
      "Epoch 193/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 20404.0996\n",
      "Epoch 194/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 20334.8906\n",
      "Epoch 195/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 20385.1074\n",
      "Epoch 196/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 20307.3652\n",
      "Epoch 197/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 20179.6797\n",
      "Epoch 198/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 19982.5996\n",
      "Epoch 199/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 20251.8652\n",
      "Epoch 200/200\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 20139.2598\n",
      "97/97 [==============================] - 0s 880us/step\n",
      "R^squared: 0.7725178876277143\n",
      "MSE:  20773.61758506636\n",
      "RMSE:  144.1305574299439\n",
      "MAE: 95.98986748449173\n",
      "1/1 [==============================] - 0s 120ms/step\n"
     ]
    }
   ],
   "source": [
    "model_outputs_nn2 = {}\n",
    "sample_predicted_nn2 ={}\n",
    "\n",
    "for i, (key, model) in enumerate(models.items()):\n",
    "    if key == 'MLP':\n",
    "        model, score, mse, rmse, mae=training_model(X_train_scaled2, X_test_scaled2, y_train2, y_test2 ,model)\n",
    "        model_outputs_nn2[key] = {'R-squared': score, 'MSE': mse, 'RMSE': rmse, 'MAE': mae}\n",
    "        sample_data = scaler.transform(sample3)\n",
    "        sample_predicted_nn2[key]=model.predict(sample_data)\n",
    "    else:\n",
    "        model, score, mse, rmse, mae =nn_models(X_train_scaled2, X_test_scaled2, y_train2, y_test2, model, epoch_num=200, batch_size=16)\n",
    "        model_outputs_nn2[key] = {'R-squared': score, 'MSE': mse, 'RMSE': rmse, 'MAE': mae}\n",
    "        sample_predicted_nn2[key]=model.predict(sample3)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f5024796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLP</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>RNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R-squared</th>\n",
       "      <td>0.808208</td>\n",
       "      <td>0.829607</td>\n",
       "      <td>0.772518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>17514.428531</td>\n",
       "      <td>15560.235650</td>\n",
       "      <td>20773.617585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>132.342089</td>\n",
       "      <td>124.740674</td>\n",
       "      <td>144.130557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>92.334757</td>\n",
       "      <td>86.815327</td>\n",
       "      <td>95.989867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    MLP          LSTM           RNN\n",
       "R-squared      0.808208      0.829607      0.772518\n",
       "MSE        17514.428531  15560.235650  20773.617585\n",
       "RMSE         132.342089    124.740674    144.130557\n",
       "MAE           92.334757     86.815327     95.989867"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_outputs_nn2 = pd.DataFrame(model_outputs_nn2)\n",
    "model_outputs_nn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9bc70801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MLP': array([ 226.41790393,  629.8616885 ,  693.95025421, 1256.72970217,\n",
       "         407.72008236,  535.9172803 ,  619.76438388,  695.20241333,\n",
       "         576.22353849,  564.64696536,  242.07330215]),\n",
       " 'LSTM': array([[39.393127],\n",
       "        [31.703161],\n",
       "        [33.75795 ],\n",
       "        [26.254454],\n",
       "        [34.082535],\n",
       "        [37.93837 ],\n",
       "        [35.941097],\n",
       "        [35.847782],\n",
       "        [32.09632 ],\n",
       "        [31.499521],\n",
       "        [34.789482]], dtype=float32),\n",
       " 'RNN': array([[283.1871],\n",
       "        [283.1871],\n",
       "        [283.1871],\n",
       "        [283.1871],\n",
       "        [283.1871],\n",
       "        [283.1871],\n",
       "        [283.1871],\n",
       "        [283.1871],\n",
       "        [283.1871],\n",
       "        [283.1871],\n",
       "        [283.1871]], dtype=float32)}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_predicted_nn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3c22e584",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_predicted_nn2['LSTM'] = sample_predicted_nn2['LSTM'].flatten()\n",
    "sample_predicted_nn2['RNN'] = sample_predicted_nn2['RNN'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ce17a947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prıce</th>\n",
       "      <th>MLP</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>RNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116.47</td>\n",
       "      <td>226.417904</td>\n",
       "      <td>39.393127</td>\n",
       "      <td>283.187103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>203.02</td>\n",
       "      <td>629.861688</td>\n",
       "      <td>31.703161</td>\n",
       "      <td>283.187103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1038.15</td>\n",
       "      <td>693.950254</td>\n",
       "      <td>33.757950</td>\n",
       "      <td>283.187103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1307.82</td>\n",
       "      <td>1256.729702</td>\n",
       "      <td>26.254454</td>\n",
       "      <td>283.187103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>674.56</td>\n",
       "      <td>407.720082</td>\n",
       "      <td>34.082535</td>\n",
       "      <td>283.187103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>243.50</td>\n",
       "      <td>535.917280</td>\n",
       "      <td>37.938370</td>\n",
       "      <td>283.187103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>303.87</td>\n",
       "      <td>619.764384</td>\n",
       "      <td>35.941097</td>\n",
       "      <td>283.187103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>184.08</td>\n",
       "      <td>695.202413</td>\n",
       "      <td>35.847782</td>\n",
       "      <td>283.187103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>275.78</td>\n",
       "      <td>576.223538</td>\n",
       "      <td>32.096321</td>\n",
       "      <td>283.187103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>327.88</td>\n",
       "      <td>564.646965</td>\n",
       "      <td>31.499521</td>\n",
       "      <td>283.187103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>122.03</td>\n",
       "      <td>242.073302</td>\n",
       "      <td>34.789482</td>\n",
       "      <td>283.187103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prıce          MLP       LSTM         RNN\n",
       "0    116.47   226.417904  39.393127  283.187103\n",
       "1    203.02   629.861688  31.703161  283.187103\n",
       "2   1038.15   693.950254  33.757950  283.187103\n",
       "3   1307.82  1256.729702  26.254454  283.187103\n",
       "4    674.56   407.720082  34.082535  283.187103\n",
       "5    243.50   535.917280  37.938370  283.187103\n",
       "6    303.87   619.764384  35.941097  283.187103\n",
       "7    184.08   695.202413  35.847782  283.187103\n",
       "8    275.78   576.223538  32.096321  283.187103\n",
       "9    327.88   564.646965  31.499521  283.187103\n",
       "10   122.03   242.073302  34.789482  283.187103"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_predicted_nn2 = pd.DataFrame(sample_predicted_nn2)\n",
    "real_pred_nn2=pd.concat([a[['prıce']],sample_predicted_nn2], axis=1)\n",
    "real_pred_nn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee55fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
